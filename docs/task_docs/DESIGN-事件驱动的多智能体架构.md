# News Agent 事件驱动架构设计文档

## 文档信息

| 项目 | 内容 |
|------|------|
| **文档版本** | v2.0 |
| **创建日期** | 2026-01-28 |
| **作者** | Claude |
| **状态** | 设计阶段 |
| **相关需求** | [需求分析.md](./需求分析.md) - B级/S级需求 |
| **核心理念** | 从"URL驱动"到"事件驱动" |

---

## 目录

- [一、核心概念转变](#一核心概念转变)
- [二、完整流程设计](#二完整流程设计)
- [三、数据模型设计](#三数据模型设计)
- [四、架构设计](#四架构设计)
- [五、组件详细设计](#五组件详细设计)
- [六、并行执行策略](#六并行执行策略)
- [七、实现计划](#七实现计划)

---

## 一、核心概念转变

### 1.1 关键理解纠正

#### ❌ 之前的错误理解

```
新闻链接(URL) → 去重(URL) → 验证(URL) → 时间轴(URL) → 预测(URL)
```

**问题**：

- 以"URL"为处理单元
- 去重 = URL去重
- 验证/时间轴/预测都针对单个URL
- 忽略了"多条新闻报道同一件事"的现实

#### ✅ 正确的理解

```
多个新闻链接 → 聚合为"事件" → 验证(事件) → 时间轴(事件) → 预测(事件)
     ↓              ↓              ↓              ↓            ↓
  原始数据      事件聚合       多轮搜索验证    主动填补缺口   多维度分析
```

**核心理念**：

- 以"事件"(Event)为处理单元
- 一个事件 = 多个URL报道同一件事的聚合
- 验证/时间轴/预测都针对"事件"

### 1.2 核心概念定义

#### 概念1：新闻链接 (NewsLink)

**定义**：单个URL，来自某个媒体

**特点**：

- 原始数据单元
- 代表某个媒体的报道
- 包含：URL、标题、内容、来源、时间

**示例**：

```python
{
    "url": "https://cnn.com/2024/01/15/trump-iowa",
    "title": "Trump wins Iowa caucus",
    "content": "前总统特朗普在周一赢得了...",
    "source": "CNN",
    "published_at": "2024-01-15"
}
```

#### 概念2：新闻事件 (NewsEvent) ⭐️ 核心概念

**定义**：**多个URL报道同一件事**的聚合

**特点**：

- 一个事件 = 2-5个相关URL（多个来源报道同一件事）
- 有统一的标题、摘要（综合多个来源）
- 保留所有来源URL作为证据
- 代表一个独立的故事/议题

**示例**：

```python
{
    "id": "event_001",
    "title": "特朗普赢得艾奥瓦州共和党初选",
    "summary": "在1月15日举行的艾奥瓦州共和党初选中，前总统特朗普以显著优势获胜，标志着2024年大选共和党提名竞争正式开始...",
    "sources": [
        {
            "url": "https://cnn.com/...",
            "title": "Trump wins Iowa caucus",
            "source": "CNN"
        },
        {
            "url": "https://fox.com/...",
            "title": "特朗普胜出艾奥瓦",
            "source": "Fox News"
        },
        {
            "url": "https://reuters.com/...",
            "title": "Iowa caucus results",
            "source": "Reuters"
        }
    ],
    "category": "政治"
}
```

**关键点**：

- ✅ 多个URL → 一个事件（聚合）
- ✅ 统一的标题和摘要（综合）
- ✅ 保留所有来源（可追溯）
- ✅ 是后续处理的基本单元

#### 概念3：事件主题 (Topic)

**定义**：多个相关事件的集合

**示例**："美国大选"主题包含：

- 事件1：特朗普宣布参选
- 事件2：特朗普赢得艾奥瓦初选
- 事件3：新罕布什尔州初选
- 事件4：南卡罗来纳州初选
- ...

---

### 1.3 需求映射

| 需求描述 | 核心概念 | 说明 |
|---------|---------|------|
| **"去重"** | 事件聚合 | 多个URL报道同一件事 → 聚合为一个事件 |
| **"验证真伪"** | 事件验证 | 验证"这件事"是否真实，而非某个URL |
| **"构建时间轴"** | 事件时间轴 | 这个"事件"从起点到今日的发展脉络 |
| **"趋势预测"** | 事件预测 | 这个"事件"未来的发展方向 |

---

## 二、完整流程设计

### 2.1 六阶段流程

```
用户输入："收集体育运动和国际政治相关新闻"
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段1：收集 (Collect)                                      │
├──────────────────────────────────────────────────────────┤
│ 目标：获取原始新闻链接                                     │
│ 处理：                                                    │
│   ├─ 多个搜索任务并行执行（体育、政治）                    │
│   ├─ 获取大量URL (如每个类型10条 = 20个URL)              │
│   └─ 获取每个URL的内容                                    │
│ 输出：20条 NewsLink                                       │
└──────────────────────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段2：聚合 (Aggregate) ⭐️ 核心阶段                       │
├──────────────────────────────────────────────────────────┤
│ 目标：将多个URL聚合为"事件"                                │
│ 处理：                                                    │
│   ├─ 分析相似度（哪些新闻在讲同一件事？）                  │
│   ├─ 聚合为"事件"（多个URL → 1个事件）                    │
│   ├─ 为每个事件生成：                                     │
│   │   ├─ 统一标题（综合多个来源）                          │
│   │   ├─ 统一摘要（综合多个来源）                          │
│   │   └─ 来源列表（所有相关URL）                          │
│   └─ 事件分类（体育类事件、政治类事件）                    │
│ 输出：6-8个 NewsEvent                                     │
└──────────────────────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段3：验证 (Validate) - 针对每个事件 ⭐️                 │
├──────────────────────────────────────────────────────────┤
│ 目标：验证每个事件的真实性                                 │
│ 处理：【并行处理每个事件】                                │
│   每个事件独立进行：                                      │
│   ├─ 初步分析：这个事件是真是假？                         │
│   ├─ 规划验证策略：需要搜索什么来验证？                   │
│   ├─ 多轮搜索验证（5-8轮）：                              │
│   │   ├─ 搜索辟谣                                        │
│   │   ├─ 搜索其他来源                                    │
│   │   ├─ 验证数据/事实                                   │
│   │   └─ 评估发布媒体可信度                              │
│   └─ 综合判断：给出可信度评分和证据链                     │
│ 输出：每个事件的 ValidationResult                         │
└──────────────────────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段4：时间轴 (Timeline) - 针对每个事件 ⭐️               │
├──────────────────────────────────────────────────────────┤
│ 目标：构建每个事件的发展脉络                               │
│ 处理：【并行处理每个事件】                                │
│   每个事件独立进行：                                      │
│   ├─ 初步梳理：按时间排序已有信息                         │
│   ├─ 识别缺口：哪些时间段信息不足？                       │
│   ├─ 主动搜索补充（5-10轮）：                            │
│   │   ├─ 填补时间缺口                                    │
│   │   ├─ 深化关键节点                                    │
│   │   ├─ 探索背景原因                                    │
│   │   └─ 追踪影响后果                                    │
│   └─ 构建完整时间轴：                                    │
│       ├─ 关键时间点                                      │
│       ├─ 因果关系                                        │
│       └─ 演进脉络                                        │
│ 输出：每个事件的 Timeline                                 │
└──────────────────────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段5：预测 (Predict) - 针对每个事件 ⭐️                 │
├──────────────────────────────────────────────────────────┤
│ 目标：预测每个事件的未来发展                               │
│ 处理：【并行处理每个事件】                                │
│   每个事件独立进行：                                      │
│   ├─ 分析当前态势                                        │
│   ├─ 规划预测策略：需要什么信息来预测？                   │
│   ├─ 多轮搜索研究（5-8轮）：                             │
│   │   ├─ 历史类似案例                                    │
│   │   ├─ 专家观点                                        │
│   │   ├─ 驱动因素分析                                    │
│   │   ├─ 风险因素识别                                    │
│   │   └─ 数据支撑                                        │
│   └─ 构建多情景预测：                                    │
│       ├─ 基准情景（最可能）                              │
│       ├─ 乐观情景                                        │
│       └─ 悲观情景                                        │
│ 输出：每个事件的 Prediction                               │
└──────────────────────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────────────────────┐
│ 阶段6：报告生成 (Report)                                  │
├──────────────────────────────────────────────────────────┤
│ 整合所有结果，生成最终报告：                              │
│   ├─ 按类型组织（体育、政治）                            │
│   ├─ 每个事件一个MD文件                                  │
│   │   ├─ 事件标题和摘要                                  │
│   │   ├─ 来源列表（所有相关URL）                         │
│   │   ├─ 可信度评分                                      │
│   │   ├─ 证据链                                          │
│   │   ├─ 时间轴                                          │
│   │   └─ 预测                                            │
│   └─ 生成索引和汇总                                      │
└──────────────────────────────────────────────────────────┘
```

### 2.2 实例演示

#### 用户输入

```
"收集体育运动和国际政治相关新闻"
```

#### 阶段1：收集

```
并行搜索：
  - 体育运动 → 10个URL
  - 国际政治 → 10个URL

获取内容：
  - 20个URL → 20条 NewsLink
```

#### 阶段2：聚合

```
分析20个NewsLink，识别相似度：

体育类：
  - URL1-3 都在讲"冬奥会中国代表团成立" → 聚合为 事件1
  - URL4-6 都在讲"某冰球比赛" → 聚合为 事件2
  - URL7-8 都在讲"某篮球赛事" → 聚合为 事件3

政治类：
  - URL9-12 都在讲"特朗普艾奥瓦初选" → 聚合为 事件4
  - URL13-15 都在讲"国际金价上涨" → 聚合为 事件5
  - URL16-20 都在讲"某国际会议" → 聚合为 事件6

输出：6个 NewsEvent，每个包含2-5个来源
```

#### 阶段3-5：并行处理每个事件

```
并行执行 6 个事件的处理：

事件1（冬奥会）：
  ├─ Validator：搜索验证 → 可信度 85分
  ├─ Timeline：搜索历史 → 构建时间轴
  └─ Predictor：搜索预测 → 多情景预测

事件2（冰球比赛）：
  ├─ Validator → ...
  ├─ Timeline → ...
  └─ Predictor → ...

...（6个事件同时进行）
```

#### 阶段6：报告生成

```
report/
├── 体育运动/
│   ├── 事件1：冬奥会中国代表团成立.md
│   │   ├─ 标题和摘要
│   │   ├─ 来源：[CNN, 新华网, 路透社]
│   │   ├─ 可信度：85分
│   │   ├─ 证据链：...
│   │   ├─ 时间轴：...
│   │   └─ 预测：...
│   ├── 事件2：冰球比赛.md
│   └── 索引.md
└── 国际政治/
    ├── 事件4：特朗普艾奥瓦初选.md
    ├── 事件5：国际金价上涨.md
    └── 索引.md
```

---

## 三、数据模型设计

### 3.1 NewsLink（新闻链接）

```python
class NewsLink(TypedDict):
    """单个新闻链接"""
    url: str                    # URL
    title: str                  # 标题
    content: str                # 内容
    source: str                 # 来源媒体
    published_at: str           # 发布时间
    category: str               # 分类（体育/政治）
    collected_at: str           # 收集时间
```

### 3.2 NewsEvent（新闻事件）⭐️ 核心模型

```python
class NewsEvent(TypedDict):
    """新闻事件（多个URL的聚合）"""

    # ========== 基本信息 ==========
    id: str                     # 事件ID (event_001)
    title: str                  # 统一标题（综合多个来源）
    summary: str                # 统一摘要（综合多个来源）
    category: str               # 分类（体育/政治）

    # ========== 来源列表 ==========
    sources: List[NewsLink]     # 这个事件的所有来源URL
    """
    示例：
    sources = [
        {url: "cnn.com/...", title: "Trump wins Iowa", ...},
        {url: "fox.com/...", title: "特朗普胜出", ...},
        {url: "reuters.com/...", title: "Iowa caucus", ...}
    ]
    """

    # ========== 验证结果 ==========
    validation: Optional[ValidationResult]
    """
    {
        "credibility_score": 85,  # 可信度 0-100
        "evidence_chain": [       # 证据链
            "搜索辟谣：未发现",
            "其他来源：发现3个类似报道",
            "媒体可信度：权威媒体"
        ],
        "validation_rounds": 5    # 验证轮数
    }
    """

    # ========== 时间轴 ==========
    timeline: Optional[Timeline]
    """
    {
        "milestones": [
            {"date": "2024-01-15", "event": "宣布参选", "importance": "高"},
            {"date": "2024-01-25", "event": "赢得艾奥瓦初选", "importance": "高"}
        ],
        "causality": "参选 → 初选 → ...",
        "narrative": "完整发展脉络...",
        "research_rounds": 8      # 研究轮数
    }
    """

    # ========== 预测 ==========
    prediction: Optional[Prediction]
    """
    {
        "scenarios": [
            {"name": "基准情景", "probability": 0.6, "description": "..."},
            {"name": "乐观情景", "probability": 0.25, "description": "..."},
            {"name": "悲观情景", "probability": 0.15, "description": "..."}
        ],
        "key_factors": ["因素1", "因素2"],
        "risks": ["风险1", "风险2"],
        "research_rounds": 6      # 研究轮数
    }
    """
```

### 3.3 ValidationResult（验证结果）

```python
class ValidationResult(TypedDict):
    """事件验证结果"""
    credibility_score: int       # 可信度 0-100
    evidence_chain: List[str]    # 证据链（每一步验证的发现）
    validation_rounds: int       # 验证轮数
    confidence_level: str        # 置信度等级（高/中/低）
    key_findings: List[str]      # 关键发现
```

### 3.4 Timeline（时间轴）

```python
class Timeline(TypedDict):
    """事件时间轴"""
    milestones: List[Dict[str, Any]]  # 关键节点
    """
    [
        {"date": "2024-01-15", "event": "宣布参选", "importance": "高", "sources": [...]},
        {"date": "2024-01-25", "event": "赢得艾奥瓦初选", "importance": "高", "sources": [...]}
    ]
    """
    causality: str              # 因果关系描述
    narrative: str              # 完整发展脉络
    research_rounds: int        # 研究轮数
    gaps_filled: int            # 填补的缺口数量
```

### 3.5 Prediction（预测）

```python
class Prediction(TypedDict):
    """事件预测"""
    scenarios: List[Dict[str, Any]]  # 情景预测
    """
    [
        {"name": "基准情景", "probability": 0.6, "description": "...", "assumptions": [...]},
        {"name": "乐观情景", "probability": 0.25, "description": "..."},
        {"name": "悲观情景", "probability": 0.15, "description": "..."}
    ]
    """
    key_factors: List[str]      # 关键因素
    risks: List[str]            # 风险因素
    research_rounds: int        # 研究轮数
    prediction_horizon: str     # 预测时间范围（如"未来3个月"）
```

---

## 四、架构设计

### 4.1 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                  事件驱动的多智能体架构                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  用户输入                                                    │
│    ↓                                                        │
│  ┌───────────────────────────────────────────┐             │
│  │  Coordinator (任务协调)                   │             │
│  │                                           │             │
│  │  职责：                                    │             │
│  │  - 理解用户意图（体育、政治等）            │             │
│  │  - 生成搜索任务列表                       │             │
│  │  - 协调各阶段执行                         │             │
│  └─────────────┬─────────────────────────────┘             │
│                ↓                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  阶段1：收集 (Collection)                           │   │
│  │                                                      │   │
│  │  并行执行：                                           │   │
│  │    ├─ Searcher (体育)    → 10个URL                  │   │
│  │    └─ Searcher (政治)    → 10个URL                  │   │
│  │                                                      │   │
│  │    ├─ ContentFetcher (并行10个) → 获取内容           │   │
│  │                                                      │   │
│  │  输出：20个 NewsLink                                 │   │
│  └──────────────────┬──────────────────────────────────┘   │
│                     ↓                                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  阶段2：聚合 (Aggregation) ⭐️ 核心阶段              │   │
│  │                                                      │   │
│  │  EventAggregator Agent                               │   │
│  │    ├─ 分析相似度                                     │   │
│  │    ├─ 聚合为事件（多个URL → 1个事件）                │   │
│  │    ├─ 生成统一标题和摘要                             │   │
│  │    └─ 保留所有来源                                   │   │
│  │                                                      │   │
│  │  输出：6-8个 NewsEvent（每个包含2-5个来源）          │   │
│  └──────────────────┬──────────────────────────────────┘   │
│                     ↓                                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  阶段3-5：深度分析（针对每个事件并行）⭐️            │   │
│  │                                                      │   │
│  │  事件1          事件2          事件3                │   │
│  │    ├─ Validator    ├─ Validator    ├─ Validator     │   │
│  │    ├─ Timeline     ├─ Timeline     ├─ Timeline      │   │
│  │    └─ Predictor    └─ Predictor    └─ Predictor     │   │
│  │                                                      │   │
│  │  （每个事件独立并行处理）                             │   │
│  │                                                      │   │
│  │  输出：每个事件的 validation + timeline + prediction │   │
│  └──────────────────┬──────────────────────────────────┘   │
│                     ↓                                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  阶段6：报告生成 (Report)                            │   │
│  │                                                      │   │
│  │  Synthesizer Agent                                   │   │
│  │    ├─ 按类型组织（体育、政治）                       │   │
│  │    ├─ 生成每个事件的MD文件                           │   │
│  │    └─ 生成索引和汇总                                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 4.2 架构优势

| 维度 | URL驱动架构 | 事件驱动架构 |
|------|------------|------------|
| **处理单元** | 单个URL | 事件（多个URL聚合） |
| **去重** | URL去重 | 事件聚合（同一件事） |
| **验证对象** | 某个URL的真假 | 某个事件的真实性 |
| **时间轴** | 某个URL的历史 | 事件的发展脉络 |
| **预测** | 某个URL的未来 | 事件的未来发展 |
| **并行级别** | URL级别 | 事件级别 |
| **信息完整性** | 低（单一来源） | 高（多源综合） |
| **可信度** | 低（无法交叉验证） | 高（多源验证） |

---

## 五、组件详细设计

### 5.1 Searcher Agent（搜索器）

**职责**：

- 接收搜索任务（关键词、数量）
- 调用百度搜索工具
- 返回搜索结果（元数据列表）

**系统提示词**：

```
你是新闻搜索专家。

任务：使用百度搜索工具搜索新闻

步骤：
1. 从任务中提取关键词
2. 调用 baidu_news_search(query=关键词, num_results=数量)
3. 返回搜索结果（只包含元数据，不获取完整内容）

⚠️ 重要：
- 只搜索，不获取完整内容
- 返回：title, url, summary, source, time
- 不要调用 fetch_article_content
```

**工具列表**：

- `baidu_news_search`
- `baidu_search`

**输入输出**：

```python
# 输入
{"keyword": "体育运动", "num_results": 10}

# 输出
{"results": [
    {"title": "...", "url": "...", "summary": "...", "source": "...", "time": "..."}
]}
```

### 5.2 ContentFetcher Agent（内容获取器）

**职责**：

- 接收单个URL的元数据
- 获取完整内容
- 保存到数据库

**系统提示词**：

```
你是单条新闻处理器。

任务：获取单条新闻的完整内容并保存

步骤：
1. 调用 fetch_article_content(url=URL) 获取完整内容
2. 调用 save_news 保存到数据库
3. 报告结果

⚠️ 重要：
- 你只会收到一条新闻
- 处理完就结束
- 如果获取失败，使用 summary 作为备用内容
```

**工具列表**：

- `fetch_article_content`
- `save_news`

**输入输出**：

```python
# 输入
{"url": "...", "title": "...", "category": "体育"}

# 输出
{"success": true, "article_id": 123, "content_length": 3500}
```

### 5.3 EventAggregator Agent（事件聚合器）⭐️ 核心组件

**职责**：

- 将多个 NewsLink 聚合为 NewsEvent
- 分析相似度，识别同一件事
- 生成统一的标题和摘要

**系统提示词**：

```
你是新闻事件聚合专家。

任务：将多条新闻聚合为"事件"

背景：
- 多个媒体可能报道同一件事
- 需要识别哪些新闻在讲同一件事
- 将它们聚合为一个"事件"

步骤：
1. 分析所有新闻的相似度
2. 识别哪些在讲同一件事（基于：标题、内容、时间）
3. 为每个事件生成：
   - 统一标题（综合多个来源）
   - 统一摘要（综合多个来源）
   - 来源列表（所有相关URL）
4. 为事件分配分类（体育/政治）

⚠️ 重要：
- 不同主题的新闻 → 不同事件
- 同一主题的不同角度 → 可能是同一事件
- 保留所有来源URL，不要删除

示例：
输入：
  - "特朗普赢得艾奥瓦初选" (CNN)
  - "特朗普胜出艾奥瓦" (Fox)
  - "Iowa caucus results" (Reuters)

输出：
  事件：
    - 标题："特朗普赢得艾奥瓦州共和党初选"
    - 摘要："在1月15日举行的艾奥瓦州共和党初选中..."
    - 来源：[CNN, Fox, Reuters]
```

**工具列表**：

- `get_news`（从数据库获取所有NewsLink）
- `cache_set`（缓存事件）

**输入输出**：

```python
# 输入
{"news_links": [
    {url, title, content, category: "体育"},
    ...
]}

# 输出
{"events": [
    {
        id: "event_1",
        title: "xxx",
        summary: "xxx",
        category: "体育",
        sources: [link1, link2, link3]
    }
]}
```

### 5.4 Validator Agent（事件验证器）⭐️ 主动探索型

**职责**：

- 验证单个事件的真实性
- 多轮搜索、交叉验证
- 给出可信度评分和证据链

**系统提示词**（参考 [S级核心思路-自主探索型Agent.md](./S级核心思路-自主探索型Agent.md)）：

```
你是新闻真实性验证专家，采用主动探索型方法。

核心理念：
- 不是被动分析，而是主动探索
- 像侦探一样，自己决定要搜索什么来验证

工作流程：

第1步：初步分析
  ↓
  "这个事件说XXX发生了，但我不知道真假"

第2步：规划验证策略
  ↓
  "我应该：
   - 搜索一下有没有辟谣
   - 看看其他媒体怎么报道的
   - 查查发布媒体的历史可信度
   - 验证一下具体的数据"

第3步：逐个搜索验证（5-8轮）
  ↓
  搜索1："事件关键词 辟谣" → 判断
  搜索2："事件关键词" 其他来源 → 发现X个类似报道
  搜索3："发布媒体" 可信度 → 评估
  搜索4：验证具体数据 → 对比
  ...

第4步：综合判断
  ↓
  给出可信度评分（0-100）
  列出证据链（每一步的发现）
  说明置信度等级（高/中/低）

⚠️ 终止条件：
- 可信度已经很高（>80分）
- 达到最大验证轮数（8轮）
- 新搜索不再提供新信息

输入：
  事件信息（标题、摘要、来源列表）

输出：
  ValidationResult
```

**工具列表**：

- `baidu_search`（多轮搜索）
- `cache_get/set`（存储验证过程）

**输入输出**：

```python
# 输入
{"event": {
    id: "event_1",
    title: "特朗普赢得艾奥瓦初选",
    sources: [...]
}}

# 输出
{
    "credibility_score": 85,
    "evidence_chain": [
        "搜索1：未发现辟谣",
        "搜索2：发现3个其他来源类似报道",
        "搜索3：发布媒体为权威媒体",
        ...
    ],
    "validation_rounds": 5,
    "confidence_level": "高"
}
```

### 5.5 TimelineBuilder Agent（时间轴构建器）⭐️ 主动探索型

**职责**：

- 构建单个事件的发展脉络
- 主动搜索填补时间缺口
- 识别关键节点和因果关系

**系统提示词**：

```
你是事件时间轴构建专家，采用主动探索型方法。

核心理念：
- 不是简单排序已有新闻，而是主动填补缺口
- 像历史学家一样，还原完整发展脉络

工作流程：

第1步：初步梳理
  ↓
  "我有了这些新闻，按时间排序：
   - 1月15日：参选
   - 1月25日：初选
   但...15日到25日之间发生了什么？我不清楚"

第2步：识别缺口
  ↓
  "我需要：
   - 填补时间缺口（15日到25日之间）
   - 深化关键节点（初选的详细过程）
   - 探索背景原因（为什么参选？）
   - 追踪影响后果（初选结果影响了什么？）"

第3步：主动搜索补充（5-10轮）
  ↓
  搜索1："事件关键词 1月15-25日" → 发现辩论、民调
  搜索2："关键节点 详细过程" → 获得更多信息
  搜索3："事件背景 原因" → 发现背景信息
  搜索4："事件影响 后续" → 发现后续发展
  ...

第4步：构建完整时间轴
  ↓
  列出所有关键节点
  标注因果关系
  描述完整发展脉络

⚠️ 终止条件：
- 时间轴已经完整（无明显缺口）
- 达到最大研究轮数（10轮）
- 新搜索不再提供新信息

输入：
  事件信息（标题、来源列表、验证结果）

输出：
  Timeline
```

**工具列表**：

- `baidu_search`（多轮搜索）
- `cache_get/set`（存储研究过程）

### 5.6 Predictor Agent（趋势预测器）⭐️ 主动探索型

**职责**：

- 预测单个事件的未来发展
- 多维度研究、多情景预测
- 提供充分的依据和风险评估

**系统提示词**：

```
你是趋势预测专家，采用主动探索型方法。

核心理念：
- 不是简单外推，而是多维度研究
- 像投资顾问一样，给出多情景预测

工作流程：

第1步：分析当前态势
  ↓
  "金价现在是2100，最近在上涨。
   但我不确定这个趋势会持续"

第2步：规划预测策略
  ↓
  "我需要：
   - 历史上类似情况是什么结果？
   - 专家们怎么看？
   - 有哪些关键因素会影响走势？
   - 有哪些风险可能导致预测失败？"

第3步：多轮搜索研究（5-8轮）
  ↓
  搜索1："类似事件 历史案例" → 发现规律
  搜索2："事件 专家分析预测" → 了解专家看法
  搜索3："关键驱动因素" → 理解驱动因素
  搜索4："潜在风险因素" → 识别风险
  搜索5："数据支撑" → 获得数据依据
  ...

第4步：构建多情景预测
  ↓
  - 基准情景（最可能，60%）：描述 + 假设
  - 乐观情景（较好，25%）：描述 + 假设
  - 悲观情景（较差，15%）：描述 + 假设

⚠️ 终止条件：
- 所有维度都已研究
- 达到最大研究轮数（8轮）

输入：
  事件信息 + 时间轴

输出：
  Prediction
```

**工具列表**：

- `baidu_search`（多轮搜索）
- `cache_get/set`（存储研究过程）

---

## 六、并行执行策略

### 6.1 阶段内并行

#### 阶段1：收集阶段

```python
并行执行：

搜索阶段：
  ├─ Searcher(体育) ─┐
  └─ Searcher(政治) ─┼─→ 并行，2个搜索任务

获取内容阶段：
  ├─ Fetcher(URL1) ─┐
  ├─ Fetcher(URL2) ─┤
  ├─ ...           ─┼─→ 并行，10个获取任务
  └─ Fetcher(URL10)─┘
```

#### 阶段2：聚合阶段

```python
单个 EventAggregator 串行处理
（需要全局信息来判断相似度）
```

#### 阶段3-5：深度分析阶段（事件级别并行）⭐️

```python
并行执行（6-8个事件同时处理）：

事件1：                     事件2：                     事件3：
  ├─ Validator               ├─ Validator               ├─ Validator
  ├─ Timeline                ├─ Timeline                ├─ Timeline
  └─ Predictor               └─ Predictor               └─ Predictor

事件4：                     事件5：                     事件6：
  ├─ Validator               ├─ Validator               ├─ Validator
  ├─ Timeline                ├─ Timeline                ├─ Timeline
  └─ Predictor               └─ Predictor               └─ Predictor

每个事件独立处理，互不干扰
```

### 6.2 数据流转

```python
# State 演化

# 初始
{
    "query": "收集体育和政治新闻",
    "categories": ["体育", "政治"]
}

# 阶段1完成后
{
    "news_links": [
        {url, title, content, category: "体育"},  # 10条
        {url, title, content, category: "政治"},  # 10条
    ],
    "total_links": 20
}

# 阶段2完成后（聚合）
{
    "events": [
        {
            id: "event_1",
            title: "冬奥会中国代表团成立",
            category: "体育",
            sources: [link1, link2, link3]
        },
        {
            id: "event_2",
            title: "特朗普赢得艾奥瓦初选",
            category: "政治",
            sources: [link4, link5, link6]
        },
        ...  # 6-8个events
    ],
    "total_events": 6
}

# 阶段3-5完成后（深度分析）
{
    "events": [
        {
            id: "event_1",
            ...,
            validation: {credibility_score: 85},
            timeline: {milestones: [...]},
            prediction: {scenarios: [...]}
        },
        ...  # 每个事件都包含完整的分析结果
    ]
}
```

---

## 七、实现计划

### 7.1 实现阶段

#### 阶段 1：数据模型（1天）

- [ ] 定义 `NewsLink` 模型
- [ ] 定义 `NewsEvent` 模型（核心）
- [ ] 定义 `ValidationResult` 模型
- [ ] 定义 `Timeline` 模型
- [ ] 定义 `Prediction` 模型
- [ ] 扩展 `MultiAgentState`

#### 阶段 2：基础组件（3天）

- [ ] 实现 `SearcherAgent`
- [ ] 实现 `ContentFetcherAgent`
- [ ] 编写单元测试

#### 阶段 3：事件聚合（3天）⭐️ 核心功能

- [ ] 实现 `EventAggregatorAgent`
  - [ ] 相似度分析算法
  - [ ] 聚合逻辑
  - [ ] 标题和摘要生成
- [ ] 编写聚合测试
- [ ] 调试优化

#### 阶段 4：深度分析组件（5天）⭐️ S级功能

- [ ] 实现 `ValidatorAgent`（主动探索型）
  - [ ] 多轮搜索验证逻辑
  - [ ] 证据链构建
- [ ] 实现 `TimelineBuilderAgent`（主动探索型）
  - [ ] 缺口识别
  - [ ] 主动搜索补充
- [ ] 实现 `PredictorAgent`（主动探索型）
  - [ ] 多维度研究
  - [ ] 多情景预测
- [ ] 编写组件测试

#### 阶段 5：Graph节点和工作流（3天）

- [ ] 实现 `searcher_node`
- [ ] 实现 `content_fetcher_node`
- [ ] 实现 `event_aggregator_node` ⭐️
- [ ] 实现事件并行处理逻辑 ⭐️
- [ ] 更新路由逻辑

#### 阶段 6：Coordinator集成（2天）

- [ ] 更新 `coordinator_agent.py`
  - [ ] 生成搜索任务
  - [ ] 协调各阶段
- [ ] 更新 `coordinator_node.py`

#### 阶段 7：报告生成（2天）

- [ ] 实现 `SynthesizerAgent`
- [ ] 生成事件MD文件
- [ ] 生成索引和汇总

#### 阶段 8：集成测试（3天）

- [ ] 端到端测试（C级）
- [ ] 多类型并行测试（B级）
- [ ] 事件聚合测试（B级）
- [ ] 验证/时间轴/预测测试（S级）
- [ ] 性能测试
- [ ] Bug修复

**总计：22天**

### 7.2 优先级

| 任务 | 优先级 | 说明 |
|------|--------|------|
| 数据模型 | P0 | 基础 |
| Searcher/Fetcher | P0 | 收集阶段 |
| EventAggregator | P0 | 核心组件 |
| Validator | P1 | S级功能 |
| TimelineBuilder | P1 | S级功能 |
| Predictor | P1 | S级功能 |
| 事件并行处理 | P1 | 性能关键 |
| Graph节点 | P0 | 流程编排 |
| Coordinator更新 | P1 | 集成 |
| 报告生成 | P1 | 最终输出 |
| 测试 | P1 | 质量保证 |

---

## 八、关键设计决策

### 8.1 为什么采用"事件驱动"？

| 决策 | 理由 |
|------|------|
| **事件作为处理单元** | 符合现实（多个媒体报道同一件事） |
| **聚合多个URL** | 提供完整信息、交叉验证 |
| **针对事件验证** | 验证"这件事"的真假，而非某个URL |
| **针对事件构建时间轴** | 还原"事件"的发展脉络 |
| **针对事件预测** | 预测"事件"的未来走向 |

### 8.2 并行级别选择

| 选项 | 优势 | 劣势 | 选择 |
|------|------|------|------|
| **URL级别并行** | 细粒度 | 无法跨URL理解事件 | ❌ |
| **事件级别并行** | 符合语义、易于管理 | 需要先聚合 | ✅ |
| **分类级别并行** | 粒度太大 | 并行度低 | ❌ |

**选择**：事件级别并行

- 阶段1：URL级别并行（收集）
- 阶段2：串行（聚合）
- 阶段3-5：事件级别并行（深度分析）

### 8.3 主动探索 vs 被动分析

| 维度 | 被动分析 | 主动探索 | 选择 |
|------|---------|---------|------|
| **信息来源** | 单次搜索 | 多轮搜索 | ✅ |
| **主动性** | 被动接受 | 主动补充 | ✅ |
| **深度** | 表面分析 | 深入挖掘 | ✅ |
| **证据** | 缺乏证据链 | 完整证据链 | ✅ |
| **可信度** | 低 | 高 | ✅ |
| **时间** | 快 | 慢（但更可靠） | ⚠️ |
| **成本** | 低 | 高 | ⚠️ |

**选择**：主动探索型（S级需求）

- Validator、TimelineBuilder、Predictor 都采用主动探索
- 多轮搜索（5-10轮）
- 提前终止条件（充分性、收敛性）

---

## 九、风险和挑战

### 9.1 技术风险

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|---------|
| **事件聚合不准确** | 中 | 高 | 充分测试，调整相似度算法 |
| **LLM上下文超限** | 中 | 高 | 限制搜索轮数，使用缓存 |
| **主动探索成本高** | 高 | 中 | 设置最大轮数限制 |
| **并行执行冲突** | 低 | 中 | 使用异步锁机制 |

### 9.2 性能风险

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|---------|
| **处理时间长** | 高 | 中 | 事件级别并行，减少搜索轮数 |
| **API成本高** | 高 | 高 | 缓存搜索结果，控制轮数 |
| **内存占用** | 中 | 低 | 及时释放中间结果 |

---

## 十、与当前架构的兼容性

### 10.1 保留的组件

| 组件 | 保留原因 |
|------|---------|
| **Coordinator** | 任务协调逻辑 |
| **Synthesizer** | 最终报告生成 |
| **工具层** | MCP工具适配器 |
| **存储层** | 数据库和缓存 |

### 10.2 需要修改的组件

| 组件 | 修改内容 |
|------|---------|
| **ResearcherAgent** | 拆分为 Searcher + ContentFetcher + EventAggregator |
| **ValidatorAgent** | 从验证URL改为验证事件 |
| **TimelineBuilderAgent** | 从构建URL时间轴改为构建事件时间轴 |
| **PredictorAgent** | 从预测URL改为预测事件 |

### 10.3 需要新增的组件

| 组件 | 说明 |
|------|------|
| **EventAggregatorAgent** | 聚合URL为事件 |
| **NewsEvent模型** | 事件数据模型 |
| **ValidationResult模型** | 验证结果模型 |
| **Timeline模型** | 时间轴模型 |
| **Prediction模型** | 预测模型 |

---

## 十一、总结

### 11.1 核心转变

```
从：URL驱动（以单个链接为处理单元）
到：事件驱动（以聚合的事件为处理单元）
```

### 11.2 关键创新

1. **事件聚合**：多个URL → 一个事件
2. **主动探索**：多轮搜索验证，而非被动分析
3. **事件级别并行**：每个事件独立深度分析
4. **完整证据链**：验证、时间轴、预测都有充分依据

### 11.3 符合需求

| 需求 | 实现方式 |
|------|---------|
| **B级：多类型并行** | 阶段1搜索并行 + 阶段3-5事件并行 |
| **B级：去重** | 事件聚合（同一件事的多个URL） |
| **S级：验证真伪** | 针对事件多轮搜索验证 |
| **S级：时间轴** | 针对事件主动搜索补充 |
| **S级：预测** | 针对事件多情景预测 |

---

**文档结束**

*最后更新：2026-01-28*
