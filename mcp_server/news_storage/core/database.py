"""
æ•°æ®åº“ç®¡ç†å™¨ - SQLite (å¼‚æ­¥ç‰ˆæœ¬)
"""

import aiosqlite
import json
from pathlib import Path
from typing import List, Optional
from loguru import logger

from .models import NewsItem, SearchFilter


class NewsDatabase:
    """æ–°é—»æ•°æ®åº“ç®¡ç†å™¨ (å¼‚æ­¥)"""

    def __init__(self, db_path: str = "./data/news_storage.db"):
        """åˆå§‹åŒ–æ•°æ®åº“

        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        self.conn: Optional[aiosqlite.Connection] = None
        self._initialized = False

    async def _ensure_connection(self) -> aiosqlite.Connection:
        """ç¡®ä¿æ•°æ®åº“å·²è¿æ¥å’Œåˆå§‹åŒ–"""
        if not self._initialized or self.conn is None:
            await self._connect()
            await self._create_tables()
            self._initialized = True
            logger.info(f"âœ… NewsDatabase åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
        # ç±»å‹æ–­è¨€ï¼šæ­¤æ—¶ conn ä¸€å®šä¸ä¸º None
        assert self.conn is not None
        return self.conn

    async def _connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = await aiosqlite.connect(self.db_path, timeout=30)
        self.conn.row_factory = aiosqlite.Row  # æ”¯æŒå­—å…¸å¼è®¿é—®

    async def _create_tables(self):
        """åˆ›å»ºæ•°æ®è¡¨"""
        cursor = await self.conn.cursor()

        # ä¸»è¡¨
        await cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                url TEXT NOT NULL,
                summary TEXT,
                source TEXT,
                publish_time TEXT,
                author TEXT,
                event_name TEXT,
                content TEXT,
                html_content TEXT,
                keywords TEXT,
                image_urls TEXT,
                local_image_paths TEXT,
                tags TEXT,
                session_id TEXT NOT NULL DEFAULT '',
                category TEXT NOT NULL DEFAULT '',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # åˆ›å»ºç´¢å¼•
        await cursor.execute("""CREATE INDEX IF NOT EXISTS idx_news_url ON news(url)""")
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_source ON news(source)"""
        )
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_created_at ON news(created_at)"""
        )
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_publish_time ON news(publish_time)"""
        )
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_event_name ON news(event_name)"""
        )
        # æ–°å¢ç´¢å¼•ï¼šä¼šè¯å’Œç±»åˆ«
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_session ON news(session_id)"""
        )
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_category ON news(category)"""
        )
        await cursor.execute(
            """CREATE INDEX IF NOT EXISTS idx_news_session_category ON news(session_id, category)"""
        )

        await self.conn.commit()
        logger.debug("ğŸ“Š æ•°æ®è¡¨åˆ›å»ºå®Œæˆ")

    async def save_news(self, news: NewsItem, session_id: str = "", category: str = "") -> bool:
        """ä¿å­˜å•æ¡æ–°é—»ï¼ˆå…è®¸é‡å¤ï¼‰

        Args:
            news: æ–°é—»å¯¹è±¡
            session_id: ä¼šè¯ID
            category: ç±»åˆ«

        Returns:
            æ˜¯å¦æ’å…¥æ–°è®°å½•
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        try:
            news_dict = news.to_dict()
            # è¦†ç›– session_id å’Œ category
            news_dict["session_id"] = session_id
            news_dict["category"] = category

            # ç›´æ¥æ’å…¥ï¼ˆå…è®¸é‡å¤URLï¼‰
            await cursor.execute(
                """
                INSERT INTO news (
                    title, url, summary, source, publish_time, author, event_name,
                    content, html_content, keywords, image_urls, local_image_paths, tags,
                    session_id, category, created_at, updated_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    news_dict["title"],
                    news_dict["url"],
                    news_dict["summary"],
                    news_dict["source"],
                    news_dict["publish_time"],
                    news_dict["author"],
                    news_dict["event_name"],
                    news_dict["content"],
                    news_dict["html_content"],
                    news_dict["keywords"],
                    news_dict["image_urls"],
                    news_dict["local_image_paths"],
                    news_dict["tags"],
                    session_id,
                    category,
                    news_dict["created_at"],
                    news_dict["updated_at"],
                ),
            )
            logger.debug(f"âœ… æ–°å¢æ–°é—»: {news.title[:50]}")
            await conn.commit()
            return True

        except aiosqlite.Error as e:
            logger.error(f"âŒ ä¿å­˜æ–°é—»å¤±è´¥: {e}")
            await conn.rollback()
            raise

    async def save_news_batch(self, news_list: List[NewsItem]) -> dict:
        """æ‰¹é‡ä¿å­˜æ–°é—»

        Args:
            news_list: æ–°é—»å¯¹è±¡åˆ—è¡¨

        Returns:
            ç»Ÿè®¡ç»“æœ {"added": æ•°é‡, "updated": æ•°é‡, "failed": æ•°é‡}
        """
        added = 0
        updated = 0
        failed = 0

        for news in news_list:
            try:
                if await self.save_news(news):
                    added += 1
                else:
                    updated += 1
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜æ–°é—»å¤±è´¥: {news.url[:50]}, é”™è¯¯: {e}")
                failed += 1

        result = {"added": added, "updated": updated, "failed": failed}
        logger.info(f"ğŸ“Š æ‰¹é‡ä¿å­˜å®Œæˆ: {result}")
        return result

    async def get_news_by_url(
        self, url: str, session_id: str = "", category: str = ""
    ) -> Optional[NewsItem]:
        """æ ¹æ®URLè·å–æ–°é—»

        Args:
            url: æ–°é—»URL
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼Œç”¨äºç²¾ç¡®æŸ¥è¯¢ï¼‰
            category: ç±»åˆ«ï¼ˆå¯é€‰ï¼Œç”¨äºç²¾ç¡®æŸ¥è¯¢ï¼‰

        Returns:
            æ–°é—»å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›None
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        if session_id and category:
            await cursor.execute(
                """
                SELECT id, title, url, summary, source, publish_time, author, event_name,
                       content, html_content, keywords, image_urls, local_image_paths, tags,
                       session_id, category, created_at, updated_at
                FROM news WHERE url = ? AND session_id = ? AND category = ?
                """,
                (url, session_id, category),
            )
        else:
            await cursor.execute(
                """
                SELECT id, title, url, summary, source, publish_time, author, event_name,
                       content, html_content, keywords, image_urls, local_image_paths, tags,
                       session_id, category, created_at, updated_at
                FROM news WHERE url = ?
                """,
                (url,),
            )

        row = await cursor.fetchone()
        if row:
            return NewsItem.from_db_row(row)
        return None

    async def search_news(self, filter: SearchFilter) -> List[NewsItem]:
        """æœç´¢æ–°é—»ï¼ˆè‡ªåŠ¨è¿‡æ»¤ä¼šè¯å’Œç±»åˆ«ï¼‰

        Args:
            filter: æœç´¢è¿‡æ»¤å™¨ï¼ˆå¿…é¡»åŒ…å« session_idï¼‰

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        # æ„å»ºSQLæŸ¥è¯¢
        conditions = []
        params = []

        # å¼ºåˆ¶æ·»åŠ ä¼šè¯è¿‡æ»¤
        if not filter.session_id:
            logger.warning("âš ï¸ æœç´¢æ—¶æœªæä¾› session_idï¼Œå¯èƒ½è¿”å›æ‰€æœ‰æ•°æ®")
        else:
            conditions.append("session_id = ?")
            params.append(filter.session_id)

        # æ·»åŠ ç±»åˆ«è¿‡æ»¤
        if filter.category:
            conditions.append("category = ?")
            params.append(filter.category)

        # æ™ºèƒ½æœç´¢ï¼šæ¯ä¸ªè¯åœ¨æ‰€æœ‰å­—æ®µä¸­ç‹¬ç«‹æœç´¢ï¼ˆORå…³ç³»ï¼‰
        if filter.search_terms:
            # ä¸ºæ¯ä¸ªæœç´¢è¯æ„å»ºæ¡ä»¶ï¼š(æ ‡é¢˜ OR æ‘˜è¦ OR keywordså­—æ®µ OR å†…å®¹)
            term_conditions = []
            for term in filter.search_terms:
                term_pattern = f"%{term}%"
                # æ¯ä¸ªè¯åœ¨4ä¸ªå­—æ®µä¸­æœç´¢
                term_conditions.append(
                    """(
                    title LIKE ? OR
                    summary LIKE ? OR
                    keywords LIKE ? OR
                    content LIKE ?
                )"""
                )
                params.extend([term_pattern, term_pattern, f'%"{term}"%', term_pattern])

            # å¤šä¸ªè¯ä¹‹é—´æ˜¯ OR å…³ç³»ï¼šæ»¡è¶³ä»»æ„ä¸€ä¸ªè¯å³å¯
            conditions.append(f"({' OR '.join(term_conditions)})")

        # æ¥æºç­›é€‰
        if filter.source:
            conditions.append("source = ?")
            params.append(filter.source)

        # äº‹ä»¶åç§°ç­›é€‰
        if filter.event_name:
            conditions.append("event_name = ?")
            params.append(filter.event_name)

        # æ—¥æœŸèŒƒå›´ç­›é€‰
        if filter.start_date:
            conditions.append("created_at >= ?")
            params.append(filter.start_date)

        if filter.end_date:
            conditions.append("created_at <= ?")
            params.append(filter.end_date)

        # æ ‡ç­¾ç­›é€‰
        if filter.tags:
            tag_conditions = []
            for tag in filter.tags:
                tag_conditions.append("tags LIKE ?")
                params.append(f'%"{tag}"%')
            conditions.append(f"({' OR '.join(tag_conditions)})")

        # ç»„åˆWHEREå­å¥
        where_clause = ""
        if conditions:
            where_clause = "WHERE " + " AND ".join(conditions)

        # æ‰§è¡ŒæŸ¥è¯¢
        query = f"""
            SELECT id, title, url, summary, source, publish_time, author, event_name,
                   content, html_content, keywords, image_urls, local_image_paths, tags,
                   session_id, category, created_at, updated_at
            FROM news
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """

        params.extend([filter.limit, filter.offset])

        await cursor.execute(query, params)
        rows = await cursor.fetchall()

        return [NewsItem.from_db_row(row) for row in rows]

    async def get_recent_news(
        self, limit: int = 100, offset: int = 0, session_id: str = ""
    ) -> List[NewsItem]:
        """è·å–æœ€è¿‘æ·»åŠ çš„æ–°é—»

        Args:
            limit: è¿”å›æ•°é‡
            offset: åç§»é‡
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼Œæä¾›åˆ™åªè¿”å›è¯¥ä¼šè¯çš„æ–°é—»ï¼‰

        Returns:
            æ–°é—»åˆ—è¡¨
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        if session_id:
            await cursor.execute(
                """
                SELECT id, title, url, summary, source, publish_time, author, event_name,
                       content, html_content, keywords, image_urls, local_image_paths, tags,
                       session_id, category, created_at, updated_at
                FROM news
                WHERE session_id = ?
                ORDER BY created_at DESC
                LIMIT ? OFFSET ?
                """,
                (session_id, limit, offset),
            )
        else:
            await cursor.execute(
                """
                SELECT id, title, url, summary, source, publish_time, author, event_name,
                       content, html_content, keywords, image_urls, local_image_paths, tags,
                       session_id, category, created_at, updated_at
                FROM news
                ORDER BY created_at DESC
                LIMIT ? OFFSET ?
                """,
                (limit, offset),
            )

        rows = await cursor.fetchall()
        return [NewsItem.from_db_row(row) for row in rows]

    async def update_news_content(
        self, url: str, content: str, html_content: str = ""
    ) -> bool:
        """æ›´æ–°æ–°é—»å†…å®¹

        Args:
            url: æ–°é—»URL
            content: çº¯æ–‡æœ¬å†…å®¹
            html_content: HTMLå†…å®¹ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()
        await cursor.execute(
            """
            UPDATE news
            SET content = ?, html_content = ?, updated_at = CURRENT_TIMESTAMP
            WHERE url = ?
            """,
            (content, html_content, url),
        )

        await conn.commit()
        success = cursor.rowcount > 0

        if success:
            logger.debug(f"ğŸ“ æ›´æ–°å†…å®¹: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»: {url[:50]}")

        return success

    async def update_event_name(self, url: str, event_name: str) -> bool:
        """æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§°

        Args:
            url: æ–°é—»URL
            event_name: äº‹ä»¶åç§°

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()
        await cursor.execute(
            """
            UPDATE news
            SET event_name = ?, updated_at = CURRENT_TIMESTAMP
            WHERE url = ?
            """,
            (event_name, url),
        )

        await conn.commit()
        success = cursor.rowcount > 0

        if success:
            logger.debug(f"ğŸ“ æ›´æ–°äº‹ä»¶åç§°: {url[:50]} -> {event_name}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»: {url[:50]}")

        return success

    async def batch_update_event_name(self, urls: List[str], event_name: str) -> dict:
        """æ‰¹é‡æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§°

        Args:
            urls: æ–°é—»URLåˆ—è¡¨
            event_name: äº‹ä»¶åç§°

        Returns:
            ç»Ÿè®¡ç»“æœ {"updated": æ›´æ–°æ•°é‡, "failed": å¤±è´¥æ•°é‡}
        """
        updated = 0
        failed = 0

        for url in urls:
            if await self.update_event_name(url, event_name):
                updated += 1
            else:
                failed += 1

        result = {"updated": updated, "failed": failed}
        logger.info(f"ğŸ“Š æ‰¹é‡æ›´æ–°äº‹ä»¶åç§°å®Œæˆ: {result}")
        return result

    async def delete_news(self, url: str) -> bool:
        """åˆ é™¤æ–°é—»

        Args:
            url: æ–°é—»URL

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()
        await cursor.execute("DELETE FROM news WHERE url = ?", (url,))

        await conn.commit()
        success = cursor.rowcount > 0

        if success:
            logger.debug(f"ğŸ—‘ï¸ åˆ é™¤æ–°é—»: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»: {url[:50]}")

        return success

    async def get_stats(self, session_id: str = "") -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Args:
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼Œæä¾›åˆ™åªç»Ÿè®¡è¯¥ä¼šè¯ï¼‰

        Returns:
            ç»Ÿè®¡æ•°æ®
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        # æ€»æ•°
        if session_id:
            await cursor.execute("SELECT COUNT(*) FROM news WHERE session_id = ?", (session_id,))
        else:
            await cursor.execute("SELECT COUNT(*) FROM news")
        total = (await cursor.fetchone())[0]

        # æŒ‰æ¥æºç»Ÿè®¡
        if session_id:
            await cursor.execute(
                """
                SELECT source, COUNT(*) as count
                FROM news
                WHERE session_id = ?
                GROUP BY source
                ORDER BY count DESC
                LIMIT 10
            """,
                (session_id,),
            )
        else:
            await cursor.execute(
                """
                SELECT source, COUNT(*) as count
                FROM news
                GROUP BY source
                ORDER BY count DESC
                LIMIT 10
            """
            )
        by_source = {row[0]: row[1] for row in await cursor.fetchall()}

        # æœ€è¿‘7å¤©æ·»åŠ æ•°é‡
        if session_id:
            await cursor.execute(
                """
                SELECT COUNT(*) FROM news
                WHERE session_id = ? AND created_at >= datetime('now', '-7 days')
            """,
                (session_id,),
            )
        else:
            await cursor.execute(
                """
                SELECT COUNT(*) FROM news
                WHERE created_at >= datetime('now', '-7 days')
            """
            )
        recent_week = (await cursor.fetchone())[0]

        return {
            "total": total,
            "by_source": by_source,
            "recent_week": recent_week,
            "db_path": str(self.db_path),
        }

    async def get_categories(self, session_id: str) -> List[dict]:
        """è·å–ä¼šè¯ä¸­çš„æ‰€æœ‰ç±»åˆ«åŠç»Ÿè®¡

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ç±»åˆ«åˆ—è¡¨ï¼š[{"name": "ç§‘æŠ€", "count": 85, "events": 12}, ...]
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        await cursor.execute(
            """
            SELECT
                category,
                COUNT(*) as count,
                COUNT(DISTINCT event_name) as events
            FROM news
            WHERE session_id = ?
            GROUP BY category
            ORDER BY count DESC
        """,
            (session_id,),
        )

        rows = await cursor.fetchall()
        return [
            {"name": row[0], "count": row[1], "events": row[2]} for row in rows
        ]

    async def get_events_by_category(
        self, session_id: str, category: str, limit: int = 20
    ) -> List[dict]:
        """è·å–ç±»åˆ«ä¸‹çš„äº‹ä»¶åˆ—è¡¨

        Args:
            session_id: ä¼šè¯ID
            category: ç±»åˆ«åç§°
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        await cursor.execute(
            """
            SELECT
                event_name,
                COUNT(*) as news_count,
                MAX(publish_time) as latest_time,
                GROUP_CONCAT(DISTINCT source) as sources
            FROM news
            WHERE session_id = ? AND category = ?
            GROUP BY event_name
            ORDER BY latest_time DESC
            LIMIT ?
        """,
            (session_id, category, limit),
        )

        rows = await cursor.fetchall()
        return [
            {
                "event_name": row[0],
                "news_count": row[1],
                "latest_time": row[2],
                "sources": (row[3] or "").split(",") if row[3] else [],
            }
            for row in rows
        ]

    async def get_news_titles_by_event(
        self, session_id: str, event_name: str, limit: int = 50
    ) -> List[dict]:
        """è·å–äº‹ä»¶ä¸‹çš„æ–°é—»æ ‡é¢˜åˆ—è¡¨ï¼ˆè½»é‡çº§ï¼‰

        Args:
            session_id: ä¼šè¯ID
            event_name: äº‹ä»¶åç§°
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            æ–°é—»åˆ—è¡¨ï¼ˆè½»é‡çº§ï¼ŒåŒ…å«å›¾ç‰‡URLï¼‰
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        await cursor.execute(
            """
            SELECT
                title, url, summary, source, publish_time, author, image_urls
            FROM news
            WHERE session_id = ? AND event_name = ?
            ORDER BY publish_time DESC
            LIMIT ?
        """,
            (session_id, event_name, limit),
        )

        rows = await cursor.fetchall()
        return [
            {
                "title": row[0],
                "url": row[1],
                "summary": row[2] or "",
                "source": row[3] or "",
                "publish_time": row[4] or "",
                "author": row[5] or "",
                "image_urls": json.loads(row[6]) if row[6] else [],
            }
            for row in rows
        ]

    async def get_images_by_event(
        self, session_id: str, event_name: str
    ) -> List[dict]:
        """è·å–äº‹ä»¶ä¸‹æ‰€æœ‰æ–°é—»çš„å›¾ç‰‡URL

        Args:
            session_id: ä¼šè¯ID
            event_name: äº‹ä»¶åç§°

        Returns:
            å›¾ç‰‡åˆ—è¡¨ï¼š[{url, source_news_title, source_news_url}, ...]
        """
        conn = await self._ensure_connection()
        cursor = await conn.cursor()

        await cursor.execute(
            """
            SELECT
                title, url, image_urls
            FROM news
            WHERE session_id = ? AND event_name = ? AND image_urls IS NOT NULL AND image_urls != '[]'
        """,
            (session_id, event_name),
        )

        rows = await cursor.fetchall()
        images = []

        for row in rows:
            title, url, image_urls_json = row
            if image_urls_json:
                image_urls = json.loads(image_urls_json)
                for img_url in image_urls:
                    images.append(
                        {
                            "url": img_url,
                            "source_news_title": title,
                            "source_news_url": url,
                        }
                    )

        return images

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            await self.conn.close()
            self.conn = None
            self._initialized = False
            logger.info("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ"""
        await self._ensure_connection()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ"""
        await self.close()


# å…¨å±€æ•°æ®åº“å®ä¾‹
_db_instance: Optional[NewsDatabase] = None


async def get_database(db_path: str = "./data/news_storage.db") -> NewsDatabase:
    """è·å–æ•°æ®åº“å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        db_path: æ•°æ®åº“è·¯å¾„

    Returns:
        æ•°æ®åº“å®ä¾‹
    """
    global _db_instance

    if _db_instance is None:
        _db_instance = NewsDatabase(db_path)
        await _db_instance._ensure_connection()

    return _db_instance
