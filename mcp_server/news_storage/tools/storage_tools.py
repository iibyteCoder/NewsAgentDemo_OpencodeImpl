"""
æ–°é—»å­˜å‚¨å·¥å…·å‡½æ•°
"""

import json
from typing import Optional
from loguru import logger

from ..core.database import get_database
from ..core.models import NewsItem, SearchFilter


async def save_news_tool(
    title: str,
    url: str,
    summary: str = "",
    source: str = "",
    publish_time: str = "",
    author: str = "",
    event_name: str = "",
    content: str = "",
    html_content: str = "",
    keywords: str = "[]",
    images: str = "[]",
    tags: str = "[]",
) -> str:
    """ä¿å­˜å•æ¡æ–°é—» - ğŸ’¾ è‡ªåŠ¨å»é‡ï¼ˆåŸºäºURLï¼‰

    åŠŸèƒ½ï¼š
    - ä¿å­˜æ–°é—»çš„å®Œæ•´ä¿¡æ¯åˆ°SQLiteæ•°æ®åº“
    - è‡ªåŠ¨æ£€æµ‹URLæ˜¯å¦å·²å­˜åœ¨ï¼Œå­˜åœ¨åˆ™æ›´æ–°
    - æ”¯æŒä¿å­˜æ ‡é¢˜ã€æ‘˜è¦ã€æ¥æºã€æ—¶é—´ã€å†…å®¹ç­‰å®Œæ•´ä¿¡æ¯
    - æ”¯æŒå…³é”®è¯ã€å›¾ç‰‡URLï¼ˆå¤šä¸ªï¼‰ã€æ ‡ç­¾ç­‰æ‰©å±•ä¿¡æ¯
    - æ”¯æŒäº‹ä»¶åç§°å½’ç±»

    Args:
        title: æ–°é—»æ ‡é¢˜ï¼ˆå¿…å¡«ï¼‰
        url: æ–°é—»URLï¼ˆå¿…å¡«ï¼Œç”¨ä½œå”¯ä¸€æ ‡è¯†ï¼‰
        summary: æ–°é—»æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
        source: æ–°é—»æ¥æºï¼ˆå¯é€‰ï¼Œå¦‚"æ–°åç½‘"ï¼‰
        publish_time: å‘å¸ƒæ—¶é—´ï¼ˆå¯é€‰ï¼ŒåŸå§‹å­—ç¬¦ä¸²ï¼‰
        author: ä½œè€…ï¼ˆå¯é€‰ï¼‰
        event_name: äº‹ä»¶åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºå½’ç±»åŒä¸€äº‹ä»¶çš„æ–°é—»ï¼‰
        content: å®Œæ•´å†…å®¹-çº¯æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        html_content: HTMLå†…å®¹ï¼ˆåŸæ–‡ï¼‰ï¼ˆå¯é€‰ï¼‰
        keywords: å…³é”®è¯JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œå¦‚ '["AI", "æŠ€æœ¯"]'ï¼‰
        images: å›¾ç‰‡URL JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šä¸ªå›¾ç‰‡ï¼‰
        tags: æ ‡ç­¾ JSONæ•°ç»„ï¼ˆå¯é€‰ï¼‰

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - action: "inserted" æˆ– "updated"
        - message: ç»“æœæ¶ˆæ¯
        - url: æ–°é—»URL

    Examples:
        >>> # ä¿å­˜åŸºæœ¬æ–°é—»ä¿¡æ¯
        >>> save_news_tool(
        ...     title="AIæŠ€æœ¯çªç ´",
        ...     url="https://example.com/news/123",
        ...     summary="äººå·¥æ™ºèƒ½å–å¾—é‡å¤§çªç ´",
        ...     source="ç§‘æŠ€æ—¥æŠ¥"
        ... )
        >>> # ä¿å­˜å®Œæ•´æ–°é—»ï¼ˆåŒ…æ‹¬å†…å®¹ã€å›¾ç‰‡ã€äº‹ä»¶åç§°ï¼‰
        >>> save_news_tool(
        ...     title="AIæŠ€æœ¯çªç ´",
        ...     url="https://example.com/news/123",
        ...     summary="äººå·¥æ™ºèƒ½å–å¾—é‡å¤§çªç ´",
        ...     source="ç§‘æŠ€æ—¥æŠ¥",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶",
        ...     content="å®Œæ•´çš„æ–°é—»å†…å®¹...",
        ...     html_content="<p>HTMLåŸæ–‡</p>",
        ...     keywords='["AI", "æŠ€æœ¯"]',
        ...     images='["https://example.com/img1.jpg", "https://example.com/img2.jpg"]',
        ...     tags='["ç§‘æŠ€", "å‰æ²¿"]'
        ... )
    """
    try:
        db = get_database()

        # è§£æJSONå­—æ®µ
        keywords_list = json.loads(keywords) if keywords else []
        images_list = json.loads(images) if images else []
        tags_list = json.loads(tags) if tags else []

        # åˆ›å»ºæ–°é—»å¯¹è±¡
        news = NewsItem(
            title=title,
            url=url,
            summary=summary,
            source=source,
            publish_time=publish_time,
            author=author,
            event_name=event_name,
            content=content,
            html_content=html_content,
            keywords=keywords_list,
            images=images_list,
            tags=tags_list,
        )

        # ä¿å­˜
        is_new = db.save_news(news)

        action = "inserted" if is_new else "updated"
        message = f"æ–°é—»å·²{action}" if is_new else "æ–°é—»å·²æ›´æ–°"

        result = {
            "success": True,
            "action": action,
            "message": message,
            "url": url,
        }

        logger.info(f"âœ… {message}: {title[:50]}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–°é—»å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def save_news_batch_tool(news_list: str) -> str:
    """æ‰¹é‡ä¿å­˜æ–°é—» - ğŸ“¦ é«˜æ•ˆæ‰¹é‡å¯¼å…¥

    åŠŸèƒ½ï¼š
    - ä¸€æ¬¡æ€§ä¿å­˜å¤šæ¡æ–°é—»
    - è‡ªåŠ¨å»é‡ï¼Œå·²å­˜åœ¨çš„URLä¼šæ›´æ–°è€ŒéæŠ¥é”™
    - è¿”å›è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

    Args:
        news_list: æ–°é—»åˆ—è¡¨JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºï¼š
            [
                {
                    "title": "æ ‡é¢˜",
                    "url": "https://...",
                    "summary": "æ‘˜è¦",
                    "source": "æ¥æº",
                    ...
                },
                ...
            ]

    Returns:
        JSONæ ¼å¼çš„æ‰¹é‡æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - added: æ–°å¢æ•°é‡
        - updated: æ›´æ–°æ•°é‡
        - failed: å¤±è´¥æ•°é‡
        - total: æ€»æ•°

    Examples:
        >>> news_data = '''[
        ...     {"title": "æ–°é—»1", "url": "https://example.com/1", "source": "æ–°åç½‘"},
        ...     {"title": "æ–°é—»2", "url": "https://example.com/2", "source": "äººæ°‘ç½‘"}
        ... ]'''
        >>> save_news_batch_tool(news_data)
    """
    try:
        db = get_database()

        # è§£ææ–°é—»åˆ—è¡¨
        news_data = json.loads(news_list)
        news_items = []

        for item in news_data:
            news = NewsItem(
                title=item.get("title", ""),
                url=item.get("url", ""),
                summary=item.get("summary", ""),
                source=item.get("source", ""),
                publish_time=item.get("publish_time", ""),
                author=item.get("author", ""),
                content=item.get("content", ""),
                html_content=item.get("html_content", ""),
                keywords=item.get("keywords", []),
                images=item.get("images", []),
                tags=item.get("tags", []),
            )
            news_items.append(news)

        # æ‰¹é‡ä¿å­˜
        stats = db.save_news_batch(news_items)

        result = {
            "success": True,
            "added": stats["added"],
            "updated": stats["updated"],
            "failed": stats["failed"],
            "total": stats["added"] + stats["updated"] + stats["failed"],
        }

        logger.info(f"âœ… æ‰¹é‡ä¿å­˜å®Œæˆ: {result}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_news_by_url_tool(url: str) -> str:
    """æ ¹æ®URLè·å–æ–°é—» - ğŸ” ç²¾ç¡®æŸ¥è¯¢

    åŠŸèƒ½ï¼š
    - æ ¹æ®æ–°é—»URLç²¾ç¡®æŸ¥è¯¢
    - è¿”å›å®Œæ•´çš„æ–°é—»ä¿¡æ¯

    Args:
        url: æ–°é—»URL

    Returns:
        JSONæ ¼å¼çš„æ–°é—»æ•°æ®ï¼Œä¸å­˜åœ¨åˆ™è¿”å›null

    Examples:
        >>> get_news_by_url_tool("https://example.com/news/123")
    """
    try:
        db = get_database()
        news = db.get_news_by_url(url)

        if news:
            result = {
                "success": True,
                "found": True,
                "data": news.to_dict(),
            }
            logger.info(f"âœ… æ‰¾åˆ°æ–°é—»: {news.title[:50]}")
        else:
            result = {
                "success": True,
                "found": False,
                "data": None,
            }
            logger.info(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def search_news_tool(
    keyword: Optional[str] = None,
    source: Optional[str] = None,
    event_name: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    tags: Optional[str] = None,
    limit: int = 100,
    offset: int = 0,
) -> str:
    """æœç´¢æ–°é—» - ğŸ” æ”¯æŒå¤šæ¡ä»¶ç­›é€‰

    åŠŸèƒ½ï¼š
    - æ ¹æ®å…³é”®è¯æ¨¡ç³Šæœç´¢ï¼ˆæ ‡é¢˜ã€äº‹ä»¶åç§°ã€æ‘˜è¦ã€å†…å®¹ï¼‰
    - æŒ‰æ¥æºç­›é€‰
    - æŒ‰äº‹ä»¶åç§°ç²¾ç¡®ç­›é€‰ï¼ˆæŸ¥æ‰¾åŒä¸€äº‹ä»¶çš„æ‰€æœ‰æ–°é—»ï¼‰
    - æŒ‰æ—¥æœŸèŒƒå›´ç­›é€‰
    - æŒ‰æ ‡ç­¾ç­›é€‰ï¼ˆæ”¯æŒå¤šæ ‡ç­¾ï¼‰
    - æ”¯æŒåˆ†é¡µ

    Args:
        keyword: æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼Œæ¨¡ç³ŠåŒ¹é…æ ‡é¢˜ã€äº‹ä»¶åç§°ã€æ‘˜è¦ã€å†…å®¹ï¼‰
        source: æ¥æºç­›é€‰ï¼ˆå¯é€‰ï¼Œå¦‚"æ–°åç½‘"ï¼‰
        event_name: äº‹ä»¶åç§°ç²¾ç¡®ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼ï¼‰
        tags: æ ‡ç­¾JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œå¦‚ '["ç§‘æŠ€", "AI"]'ï¼‰
        limit: è¿”å›æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        offset: åç§»é‡ï¼ˆé»˜è®¤0ï¼Œç”¨äºåˆ†é¡µï¼‰

    Returns:
        JSONæ ¼å¼çš„æœç´¢ç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - count: ç»“æœæ•°é‡
        - results: æ–°é—»åˆ—è¡¨
        - filters: ä½¿ç”¨çš„ç­›é€‰æ¡ä»¶

    Examples:
        >>> # å…³é”®è¯æœç´¢ï¼ˆæ¨¡ç³ŠåŒ¹é…æ ‡é¢˜å’Œäº‹ä»¶åç§°ï¼‰
        >>> search_news_tool(keyword="AI", limit=10)
        >>> # æŒ‰æ¥æºæœç´¢
        >>> search_news_tool(source="æ–°åç½‘", limit=20)
        >>> # æŒ‰äº‹ä»¶åç§°ç²¾ç¡®æœç´¢
        >>> search_news_tool(event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶")
        >>> # ç»„åˆæœç´¢
        >>> search_news_tool(
        ...     keyword="æŠ€æœ¯",
        ...     source="ç§‘æŠ€æ—¥æŠ¥",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶",
        ...     tags='["ç§‘æŠ€", "å‰æ²¿"]',
        ...     limit=50
        ... )
    """
    try:
        db = get_database()

        # è§£ææ ‡ç­¾
        tags_list = json.loads(tags) if tags else None

        # æ„å»ºè¿‡æ»¤å™¨
        search_filter = SearchFilter(
            keyword=keyword,
            source=source,
            event_name=event_name,
            start_date=start_date,
            end_date=end_date,
            tags=tags_list,
            limit=limit,
            offset=offset,
        )

        # æœç´¢
        results = db.search_news(search_filter)

        result = {
            "success": True,
            "count": len(results),
            "results": [news.to_dict() for news in results],
            "filters": {
                "keyword": keyword,
                "source": source,
                "event_name": event_name,
                "start_date": start_date,
                "end_date": end_date,
                "tags": tags_list,
            },
        }

        logger.info(f"âœ… æœç´¢å®Œæˆ: æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_recent_news_tool(limit: int = 100, offset: int = 0) -> str:
    """è·å–æœ€è¿‘æ·»åŠ çš„æ–°é—» - ğŸ“° æœ€æ–°èµ„è®¯

    åŠŸèƒ½ï¼š
    - è·å–æœ€è¿‘æ·»åŠ çš„æ–°é—»åˆ—è¡¨
    - æŒ‰æ·»åŠ æ—¶é—´å€’åºæ’åˆ—
    - æ”¯æŒåˆ†é¡µ

    Args:
        limit: è¿”å›æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        offset: åç§»é‡ï¼ˆé»˜è®¤0ï¼Œç”¨äºåˆ†é¡µï¼‰

    Returns:
        JSONæ ¼å¼çš„æ–°é—»åˆ—è¡¨

    Examples:
        >>> # è·å–æœ€è¿‘100æ¡æ–°é—»
        >>> get_recent_news_tool(limit=100)
        >>> # åˆ†é¡µè·å–
        >>> get_recent_news_tool(limit=20, offset=20)  # ç¬¬2é¡µ
    """
    try:
        db = get_database()
        results = db.get_recent_news(limit, offset)

        result = {
            "success": True,
            "count": len(results),
            "results": [news.to_dict() for news in results],
        }

        logger.info(f"âœ… è·å–æœ€è¿‘æ–°é—»: {len(results)} æ¡")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ è·å–å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def update_news_content_tool(
    url: str, content: str, html_content: str = ""
) -> str:
    """æ›´æ–°æ–°é—»å†…å®¹ - âœï¸ è¡¥å……å®Œæ•´å†…å®¹

    åŠŸèƒ½ï¼š
    - æ›´æ–°å·²å­˜åœ¨æ–°é—»çš„å†…å®¹
    - ç”¨äºåç»­è¡¥å……å®Œæ•´æ­£æ–‡å†…å®¹

    Args:
        url: æ–°é—»URL
        content: çº¯æ–‡æœ¬å†…å®¹
        html_content: HTMLå†…å®¹ï¼ˆå¯é€‰ï¼‰

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> update_news_content_tool(
        ...     url="https://example.com/news/123",
        ...     content="è¿™æ˜¯å®Œæ•´çš„æ–°é—»æ­£æ–‡å†…å®¹...",
        ...     html_content="<p>è¿™æ˜¯HTMLå†…å®¹</p>"
        ... )
    """
    try:
        db = get_database()
        success = db.update_news_content(url, content, html_content)

        result = {
            "success": success,
            "message": "å†…å®¹å·²æ›´æ–°" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
        }

        if success:
            logger.info(f"âœ… æ›´æ–°å†…å®¹æˆåŠŸ: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ æ›´æ–°å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def delete_news_tool(url: str) -> str:
    """åˆ é™¤æ–°é—» - ğŸ—‘ï¸ ä»æ•°æ®åº“åˆ é™¤

    åŠŸèƒ½ï¼š
    - æ ¹æ®URLåˆ é™¤æ–°é—»
    - ä¸å¯æ¢å¤

    Args:
        url: æ–°é—»URL

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> delete_news_tool("https://example.com/news/123")
    """
    try:
        db = get_database()
        success = db.delete_news(url)

        result = {
            "success": success,
            "message": "åˆ é™¤æˆåŠŸ" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
        }

        if success:
            logger.info(f"âœ… åˆ é™¤æˆåŠŸ: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ åˆ é™¤å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ åˆ é™¤å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_news_stats_tool() -> str:
    """è·å–ç»Ÿè®¡ä¿¡æ¯ - ğŸ“Š æ•°æ®æ¦‚è§ˆ

    åŠŸèƒ½ï¼š
    - è·å–æ•°æ®åº“ä¸­çš„æ–°é—»ç»Ÿè®¡ä¿¡æ¯
    - æ€»æ•°ã€æ¥æºåˆ†å¸ƒã€è¿‘æœŸæ–°å¢ç­‰

    Returns:
        JSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®

    Examples:
        >>> get_news_stats_tool()
    """
    try:
        db = get_database()
        stats = db.get_stats()

        result = {
            "success": True,
            "stats": stats,
        }

        logger.info(f"âœ… ç»Ÿè®¡ä¿¡æ¯: æ€»æ•° {stats['total']}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def update_event_name_tool(url: str, event_name: str) -> str:
    """æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§° - ğŸ·ï¸ èšåˆåå½’ç±»

    åŠŸèƒ½ï¼š
    - å•ç‹¬æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§°å­—æ®µ
    - ç”¨äºæ–°é—»èšåˆåæ·»åŠ äº‹ä»¶åˆ†ç±»
    - ä¸ä¼šå½±å“å…¶ä»–å­—æ®µ

    Args:
        url: æ–°é—»URL
        event_name: äº‹ä»¶åç§°

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> # ä¸ºæ–°é—»æ·»åŠ äº‹ä»¶åç§°
        >>> update_event_name_tool(
        ...     url="https://example.com/news/123",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶"
        ... )
    """
    try:
        db = get_database()
        success = db.update_event_name(url, event_name)

        result = {
            "success": success,
            "message": "äº‹ä»¶åç§°å·²æ›´æ–°" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
            "url": url,
            "event_name": event_name,
        }

        if success:
            logger.info(f"âœ… æ›´æ–°äº‹ä»¶åç§°æˆåŠŸ: {url[:50]} -> {event_name}")
        else:
            logger.warning(f"âš ï¸ æ›´æ–°å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°äº‹ä»¶åç§°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def batch_update_event_name_tool(urls: str, event_name: str) -> str:
    """æ‰¹é‡æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§° - ğŸ“¦ æ‰¹é‡å½’ç±»

    åŠŸèƒ½ï¼š
    - æ‰¹é‡ä¸ºå¤šæ¡æ–°é—»è®¾ç½®ç›¸åŒçš„äº‹ä»¶åç§°
    - ç”¨äºå°†èšåˆåçš„æ–°é—»å½’ç±»åˆ°åŒä¸€äº‹ä»¶
    - è¿”å›è¯¦ç»†çš„æ›´æ–°ç»Ÿè®¡

    Args:
        urls: URLåˆ—è¡¨JSONå­—ç¬¦ä¸²ï¼ˆå¦‚ '["url1", "url2"]'ï¼‰
        event_name: äº‹ä»¶åç§°

    Returns:
        JSONæ ¼å¼çš„æ‰¹é‡æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - updated: æ›´æ–°æ•°é‡
        - failed: å¤±è´¥æ•°é‡
        - event_name: äº‹ä»¶åç§°

    Examples:
        >>> urls = '["https://example.com/news/1", "https://example.com/news/2"]'
        >>> batch_update_event_name_tool(
        ...     urls=urls,
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶"
        ... )
    """
    try:
        db = get_database()
        url_list = json.loads(urls) if urls else []

        if not url_list:
            return json.dumps(
                {"success": False, "error": "URLåˆ—è¡¨ä¸ºç©º"},
                ensure_ascii=False,
                indent=2,
            )

        stats = db.batch_update_event_name(url_list, event_name)

        result = {
            "success": True,
            "updated": stats["updated"],
            "failed": stats["failed"],
            "total": len(url_list),
            "event_name": event_name,
        }

        logger.info(f"âœ… æ‰¹é‡æ›´æ–°äº‹ä»¶åç§°å®Œæˆ: {stats}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æ›´æ–°äº‹ä»¶åç§°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )

