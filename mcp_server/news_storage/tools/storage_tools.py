"""
æ–°é—»å­˜å‚¨å·¥å…·å‡½æ•°
"""

import json
from typing import Optional
from loguru import logger

from ..core.database import get_database
from ..core.models import NewsItem, SearchFilter


async def save_news_tool(
    title: str,
    url: str,
    session_id: str,
    category: str,
    summary: str = "",
    source: str = "",
    publish_time: str = "",
    author: str = "",
    event_name: str = "",
    content: str = "",
    html_content: str = "",
    keywords: str = "[]",
    image_urls: str = "[]",
    local_image_paths: str = "[]",
    tags: str = "[]",
) -> str:
    """ä¿å­˜å•æ¡æ–°é—» - ğŸ’¾ è‡ªåŠ¨å»é‡ï¼ˆåŸºäºURLï¼‰

    åŠŸèƒ½ï¼š
    - ä¿å­˜æ–°é—»çš„å®Œæ•´ä¿¡æ¯åˆ°SQLiteæ•°æ®åº“
    - è‡ªåŠ¨æ£€æµ‹URLæ˜¯å¦å·²å­˜åœ¨ï¼Œå­˜åœ¨åˆ™æ›´æ–°
    - æ”¯æŒä¿å­˜æ ‡é¢˜ã€æ‘˜è¦ã€æ¥æºã€æ—¶é—´ã€å†…å®¹ç­‰å®Œæ•´ä¿¡æ¯
    - æ”¯æŒå…³é”®è¯ã€ç½‘ç»œå›¾ç‰‡URLã€æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è·¯å¾„ã€æ ‡ç­¾ç­‰æ‰©å±•ä¿¡æ¯
    - æ”¯æŒäº‹ä»¶åç§°å½’ç±»

    Args:
        title: æ–°é—»æ ‡é¢˜ï¼ˆå¿…å¡«ï¼‰
        url: æ–°é—»URLï¼ˆå¿…å¡«ï¼Œç”¨ä½œå”¯ä¸€æ ‡è¯†ï¼‰
        summary: æ–°é—»æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
        source: æ–°é—»æ¥æºï¼ˆå¯é€‰ï¼Œå¦‚"æ–°åç½‘"ï¼‰
        publish_time: å‘å¸ƒæ—¶é—´ï¼ˆå¯é€‰ï¼ŒåŸå§‹å­—ç¬¦ä¸²ï¼‰
        author: ä½œè€…ï¼ˆå¯é€‰ï¼‰
        event_name: äº‹ä»¶åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºå½’ç±»åŒä¸€äº‹ä»¶çš„æ–°é—»ï¼‰
        content: å®Œæ•´å†…å®¹-çº¯æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        html_content: HTMLå†…å®¹ï¼ˆåŸæ–‡ï¼‰ï¼ˆå¯é€‰ï¼‰
        keywords: å…³é”®è¯JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œå¦‚ '["AI", "æŠ€æœ¯"]'ï¼‰
        image_urls: ç½‘ç»œå›¾ç‰‡URL JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šä¸ªï¼Œå¦‚ '["https://example.com/img1.jpg", "https://example.com/img2.jpg"]'ï¼‰
        local_image_paths: æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è·¯å¾„JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šä¸ªï¼Œå¦‚ '["./data/images/img1.jpg", "./data/images/img2.jpg"]'ï¼‰
        tags: æ ‡ç­¾ JSONæ•°ç»„ï¼ˆå¯é€‰ï¼‰

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - action: "inserted" æˆ– "updated"
        - message: ç»“æœæ¶ˆæ¯
        - url: æ–°é—»URL

    Examples:
        >>> # ä¿å­˜åŸºæœ¬æ–°é—»ä¿¡æ¯
        >>> save_news_tool(
        ...     title="AIæŠ€æœ¯çªç ´",
        ...     url="https://example.com/news/123",
        ...     summary="äººå·¥æ™ºèƒ½å–å¾—é‡å¤§çªç ´",
        ...     source="ç§‘æŠ€æ—¥æŠ¥"
        ... )
        >>> # ä¿å­˜å®Œæ•´æ–°é—»ï¼ˆåŒ…æ‹¬å†…å®¹ã€å›¾ç‰‡ã€äº‹ä»¶åç§°ï¼‰
        >>> save_news_tool(
        ...     title="AIæŠ€æœ¯çªç ´",
        ...     url="https://example.com/news/123",
        ...     summary="äººå·¥æ™ºèƒ½å–å¾—é‡å¤§çªç ´",
        ...     source="ç§‘æŠ€æ—¥æŠ¥",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶",
        ...     content="å®Œæ•´çš„æ–°é—»å†…å®¹...",
        ...     html_content="<p>HTMLåŸæ–‡</p>",
        ...     keywords='["AI", "æŠ€æœ¯"]',
        ...     image_urls='["https://example.com/img1.jpg", "https://example.com/img2.jpg"]',
        ...     local_image_paths='["./report/images/img1.jpg", "./report/images/img2.jpg"]',
        ...     tags='["ç§‘æŠ€", "å‰æ²¿"]'
        ... )
    """
    try:
        db = await get_database()

        # è§£æJSONå­—æ®µ
        keywords_list = json.loads(keywords) if keywords else []
        image_urls_list = json.loads(image_urls) if image_urls else []
        local_image_paths_list = (
            json.loads(local_image_paths) if local_image_paths else []
        )
        tags_list = json.loads(tags) if tags else []

        # åˆ›å»ºæ–°é—»å¯¹è±¡
        news = NewsItem(
            title=title,
            url=url,
            summary=summary,
            source=source,
            publish_time=publish_time,
            author=author,
            event_name=event_name,
            content=content,
            html_content=html_content,
            keywords=keywords_list,
            image_urls=image_urls_list,
            local_image_paths=local_image_paths_list,
            tags=tags_list,
        )

        # ä¿å­˜ï¼ˆä¼ å…¥ session_id å’Œ categoryï¼‰
        is_new = await db.save_news(news, session_id=session_id, category=category)

        action = "inserted" if is_new else "updated"
        message = f"æ–°é—»å·²{action}" if is_new else "æ–°é—»å·²æ›´æ–°"

        result = {
            "success": True,
            "action": action,
            "message": message,
            "url": url,
        }

        logger.info(f"âœ… {message}: {title[:50]}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–°é—»å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def save_news_batch_tool(news_list: str) -> str:
    """æ‰¹é‡ä¿å­˜æ–°é—» - ğŸ“¦ é«˜æ•ˆæ‰¹é‡å¯¼å…¥

    åŠŸèƒ½ï¼š
    - ä¸€æ¬¡æ€§ä¿å­˜å¤šæ¡æ–°é—»
    - è‡ªåŠ¨å»é‡ï¼Œå·²å­˜åœ¨çš„URLä¼šæ›´æ–°è€ŒéæŠ¥é”™
    - è¿”å›è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

    Args:
        news_list: æ–°é—»åˆ—è¡¨JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºï¼š
            [
                {
                    "title": "æ ‡é¢˜",
                    "url": "https://...",
                    "summary": "æ‘˜è¦",
                    "source": "æ¥æº",
                    ...
                },
                ...
            ]

    Returns:
        JSONæ ¼å¼çš„æ‰¹é‡æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - added: æ–°å¢æ•°é‡
        - updated: æ›´æ–°æ•°é‡
        - failed: å¤±è´¥æ•°é‡
        - total: æ€»æ•°

    Examples:
        >>> news_data = '''[
        ...     {"title": "æ–°é—»1", "url": "https://example.com/1", "source": "æ–°åç½‘"},
        ...     {"title": "æ–°é—»2", "url": "https://example.com/2", "source": "äººæ°‘ç½‘"}
        ... ]'''
        >>> save_news_batch_tool(news_data)
    """
    try:
        db = await get_database()

        # è§£ææ–°é—»åˆ—è¡¨
        news_data = json.loads(news_list)
        news_items = []

        for item in news_data:
            news = NewsItem(
                title=item.get("title", ""),
                url=item.get("url", ""),
                summary=item.get("summary", ""),
                source=item.get("source", ""),
                publish_time=item.get("publish_time", ""),
                author=item.get("author", ""),
                content=item.get("content", ""),
                html_content=item.get("html_content", ""),
                keywords=item.get("keywords", []),
                image_urls=item.get("image_urls", []),
                local_image_paths=item.get("local_image_paths", []),
                tags=item.get("tags", []),
            )
            news_items.append(news)

        # æ‰¹é‡ä¿å­˜
        stats = await db.save_news_batch(news_items)

        result = {
            "success": True,
            "added": stats["added"],
            "updated": stats["updated"],
            "failed": stats["failed"],
            "total": stats["added"] + stats["updated"] + stats["failed"],
        }

        logger.info(f"âœ… æ‰¹é‡ä¿å­˜å®Œæˆ: {result}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_news_by_url_tool(
    url: str, session_id: str = "", category: str = ""
) -> str:
    """æ ¹æ®URLè·å–æ–°é—» - ğŸ” ç²¾ç¡®æŸ¥è¯¢

    åŠŸèƒ½ï¼š
    - æ ¹æ®æ–°é—»URLç²¾ç¡®æŸ¥è¯¢
    - è¿”å›å®Œæ•´çš„æ–°é—»ä¿¡æ¯

    Args:
        url: æ–°é—»URL

    Returns:
        JSONæ ¼å¼çš„æ–°é—»æ•°æ®ï¼Œä¸å­˜åœ¨åˆ™è¿”å›null

    Examples:
        >>> get_news_by_url_tool("https://example.com/news/123")
    """
    try:
        db = await get_database()
        news = await db.get_news_by_url(url, session_id=session_id, category=category)

        if news:
            # è¿”å›ç”¨æˆ·å‹å¥½çš„æ ¼å¼ï¼ˆåˆ—è¡¨å­—æ®µä¿æŒä¸ºåˆ—è¡¨ï¼Œä¸æ˜¯JSONå­—ç¬¦ä¸²ï¼‰
            result = {
                "success": True,
                "found": True,
                "data": {
                    "title": news.title,
                    "url": news.url,
                    "summary": news.summary,
                    "source": news.source,
                    "publish_time": news.publish_time,
                    "author": news.author,
                    "event_name": news.event_name,
                    "session_id": news.session_id,
                    "category": news.category,
                    "content": news.content,
                    "html_content": news.html_content,
                    "keywords": news.keywords,
                    "image_urls": news.image_urls,
                    "local_image_paths": news.local_image_paths,
                    "tags": news.tags,
                    "created_at": news.created_at,
                    "updated_at": news.updated_at,
                },
            }
            logger.info(f"âœ… æ‰¾åˆ°æ–°é—»: {news.title[:50]}")
        else:
            result = {
                "success": True,
                "found": False,
                "data": None,
            }
            logger.info(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def search_news_tool(
    session_id: str,
    search: Optional[str] = None,
    source: Optional[str] = None,
    event_name: Optional[str] = None,
    category: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    tags: Optional[str] = None,
    limit: int = 100,
    offset: int = 0,
) -> str:
    """æœç´¢æ–°é—» - ğŸ” æ™ºèƒ½æœç´¢ï¼Œä¸€ä¸ªå‚æ•°æå®šæ‰€æœ‰

    ã€æ ¸å¿ƒç‰¹æ€§ã€‘
    - è‡ªåŠ¨åˆ†è¯ï¼šå¤šä¸ªç©ºæ ¼åˆ†éš”çš„è¯ä¼šè¢«åˆ†åˆ«æœç´¢
    - å…¨å­—æ®µåŒ¹é…ï¼šæœç´¢æ ‡é¢˜ã€æ‘˜è¦ã€keywordså­—æ®µã€å†…å®¹
    - å®½æ¾åŒ¹é…ï¼šåªè¦åŒ¹é…ä»»æ„ä¸€ä¸ªè¯å°±è¿”å›è¯¥æ–°é—»ï¼ˆORå…³ç³»ï¼‰
    - ç»“æœæœ€å¤§åŒ–ï¼šå°½å¯èƒ½å¤šè¿”å›ç›¸å…³å†…å®¹

    Args:
        search: æœç´¢è¯ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šä¸ªè¯ç”¨ç©ºæ ¼åˆ†éš”ï¼‰
            - å•ä¸ªè¯ï¼š"æ¬§å† "
            - å¤šä¸ªè¯ï¼š"çš‡é©¬ å·´é»åœ£æ—¥è€³æ›¼ æ·˜æ±°èµ›"
            - ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†è¯ï¼Œæ¯ä¸ªè¯ç‹¬ç«‹æœç´¢æ‰€æœ‰å­—æ®µ
        source: æ¥æºç­›é€‰ï¼ˆå¯é€‰ï¼Œå¦‚"æ–°åç½‘"ï¼‰
        event_name: äº‹ä»¶åç§°ç²¾ç¡®ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼ï¼‰
        tags: æ ‡ç­¾JSONæ•°ç»„ï¼ˆå¯é€‰ï¼Œå¦‚ '["ç§‘æŠ€", "AI"]'ï¼‰
        limit: è¿”å›æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        offset: åç§»é‡ï¼ˆé»˜è®¤0ï¼Œç”¨äºåˆ†é¡µï¼‰

    Returns:
        JSONæ ¼å¼çš„æœç´¢ç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - count: ç»“æœæ•°é‡
        - results: æ–°é—»åˆ—è¡¨
        - filters: ä½¿ç”¨çš„ç­›é€‰æ¡ä»¶

    Examples:
        >>> # ã€æœ€ç®€å•ã€‘å•ä¸ªè¯æœç´¢
        >>> search_news_tool(search="æ¬§å† ")

        >>> # ã€å¸¸ç”¨ã€‘å¤šä¸ªè¯æœç´¢ï¼ˆè‡ªåŠ¨åˆ†è¯ï¼ŒORå…³ç³»ï¼‰
        >>> search_news_tool(search="çš‡é©¬ å·´é»åœ£æ—¥è€³æ›¼ æ·˜æ±°èµ› æ¢å¤èƒ½åŠ›")

        >>> # ã€ç²¾å‡†ã€‘æŒ‰æ¥æºç­›é€‰
        >>> search_news_tool(search="AI", source="ç§‘æŠ€æ—¥æŠ¥")

        >>> # ã€ä¸“ä¸šã€‘ç»„åˆç­›é€‰
        >>> search_news_tool(
        ...     search="AI æŠ€æœ¯ çªç ´",
        ...     source="ç§‘æŠ€æ—¥æŠ¥",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶",
        ...     start_date="2026-01-01"
        ... )

        >>> # ã€é«˜çº§ã€‘æŒ‰æ ‡ç­¾ç­›é€‰
        >>> search_news_tool(
        ...     search="æ¬§å† ",
        ...     tags='["ä½“è‚²", "è¶³çƒ"]'
        ... )
    """
    try:
        db = await get_database()

        # è‡ªåŠ¨åˆ†è¯ï¼šæŒ‰ç©ºæ ¼åˆ†å‰²æœç´¢è¯
        search_terms = None
        if search:
            # å»é™¤é¦–å°¾ç©ºæ ¼ï¼ŒæŒ‰ç©ºæ ¼åˆ†å‰²ï¼Œè¿‡æ»¤ç©ºå­—ç¬¦ä¸²
            search_terms = [term.strip() for term in search.split() if term.strip()]

        # è§£ææ ‡ç­¾
        tags_list = json.loads(tags) if tags else None

        # æ„å»ºè¿‡æ»¤å™¨
        search_filter = SearchFilter(
            session_id=session_id,
            category=category or "",
            search_terms=search_terms,
            source=source,
            event_name=event_name,
            start_date=start_date,
            end_date=end_date,
            tags=tags_list,
            limit=limit,
            offset=offset,
        )

        # æœç´¢
        results = await db.search_news(search_filter)

        # è½¬æ¢ä¸ºè½»é‡çº§æ•°æ®ï¼ˆä¸åŒ…å« content å’Œ html_contentï¼‰
        lightweight_results = []
        for news in results:
            lightweight_results.append(
                {
                    "title": news.title,
                    "url": news.url,
                    "summary": news.summary,
                    "source": news.source,
                    "publish_time": news.publish_time,
                    "author": news.author,
                    "event_name": news.event_name,
                    "keywords": news.keywords,
                    "image_urls": news.image_urls,
                    "local_image_paths": news.local_image_paths,
                    "tags": news.tags,
                    "created_at": news.created_at,
                }
            )

        result = {
            "success": True,
            "count": len(lightweight_results),
            "results": lightweight_results,
            "filters": {
                "search": search,
                "search_terms": search_terms,
                "source": source,
                "event_name": event_name,
                "category": category,
                "start_date": start_date,
                "end_date": end_date,
                "tags": tags_list,
            },
            "note": "ç»“æœä¸åŒ…å« content å’Œ html_contentï¼Œéœ€è¦æ—¶è¯·ä½¿ç”¨ news_storage_get_by_url è·å–å®Œæ•´å†…å®¹",
        }

        logger.info(f"âœ… æœç´¢å®Œæˆ: æ‰¾åˆ° {len(lightweight_results)} æ¡ç»“æœ")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_recent_news_tool(
    session_id: str, limit: int = 100, offset: int = 0
) -> str:
    """è·å–æœ€è¿‘æ·»åŠ çš„æ–°é—»ï¼ˆè½»é‡çº§ï¼Œä¸åŒ…å« contentï¼‰- ğŸ“° æœ€æ–°èµ„è®¯

    åŠŸèƒ½ï¼š
    - è·å–æœ€è¿‘æ·»åŠ çš„æ–°é—»åˆ—è¡¨
    - æŒ‰æ·»åŠ æ—¶é—´å€’åºæ’åˆ—
    - æ”¯æŒåˆ†é¡µ
    - è¿”å›è½»é‡çº§æ•°æ®ï¼ˆä¸å« content å’Œ html_contentï¼‰

    Args:
        session_id: ä¼šè¯IDï¼ˆå¿…å¡«ï¼‰
        limit: è¿”å›æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        offset: åç§»é‡ï¼ˆé»˜è®¤0ï¼Œç”¨äºåˆ†é¡µï¼‰

    Returns:
        JSONæ ¼å¼çš„æ–°é—»åˆ—è¡¨ï¼ˆè½»é‡çº§ï¼‰

    Examples:
        >>> # è·å–æœ€è¿‘100æ¡æ–°é—»
        >>> get_recent_news_tool(session_id="xxx", limit=100)
        >>> # åˆ†é¡µè·å–
        >>> get_recent_news_tool(session_id="xxx", limit=20, offset=20)  # ç¬¬2é¡µ
    """
    try:
        db = await get_database()
        results = await db.get_recent_news(limit, offset, session_id=session_id)

        # è½¬æ¢ä¸ºè½»é‡çº§æ•°æ®ï¼ˆä¸åŒ…å« content å’Œ html_contentï¼‰
        lightweight_results = []
        for news in results:
            lightweight_results.append(
                {
                    "title": news.title,
                    "url": news.url,
                    "summary": news.summary,
                    "source": news.source,
                    "publish_time": news.publish_time,
                    "author": news.author,
                    "event_name": news.event_name,
                    "keywords": news.keywords,
                    "image_urls": news.image_urls,
                    "local_image_paths": news.local_image_paths,
                    "tags": news.tags,
                    "created_at": news.created_at,
                }
            )

        result = {
            "success": True,
            "count": len(lightweight_results),
            "results": lightweight_results,
            "note": "ç»“æœä¸åŒ…å« content å’Œ html_contentï¼Œéœ€è¦æ—¶è¯·ä½¿ç”¨ news_storage_get_by_url è·å–å®Œæ•´å†…å®¹",
        }

        logger.info(f"âœ… è·å–æœ€è¿‘æ–°é—»: {len(lightweight_results)} æ¡")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ è·å–å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def update_news_content_tool(
    url: str, content: str, html_content: str = ""
) -> str:
    """æ›´æ–°æ–°é—»å†…å®¹ - âœï¸ è¡¥å……å®Œæ•´å†…å®¹

    åŠŸèƒ½ï¼š
    - æ›´æ–°å·²å­˜åœ¨æ–°é—»çš„å†…å®¹
    - ç”¨äºåç»­è¡¥å……å®Œæ•´æ­£æ–‡å†…å®¹

    Args:
        url: æ–°é—»URL
        content: çº¯æ–‡æœ¬å†…å®¹
        html_content: HTMLå†…å®¹ï¼ˆå¯é€‰ï¼‰

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> update_news_content_tool(
        ...     url="https://example.com/news/123",
        ...     content="è¿™æ˜¯å®Œæ•´çš„æ–°é—»æ­£æ–‡å†…å®¹...",
        ...     html_content="<p>è¿™æ˜¯HTMLå†…å®¹</p>"
        ... )
    """
    try:
        db = await get_database()
        success = await db.update_news_content(url, content, html_content)

        result = {
            "success": success,
            "message": "å†…å®¹å·²æ›´æ–°" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
        }

        if success:
            logger.info(f"âœ… æ›´æ–°å†…å®¹æˆåŠŸ: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ æ›´æ–°å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def delete_news_tool(url: str) -> str:
    """åˆ é™¤æ–°é—» - ğŸ—‘ï¸ ä»æ•°æ®åº“åˆ é™¤

    åŠŸèƒ½ï¼š
    - æ ¹æ®URLåˆ é™¤æ–°é—»
    - ä¸å¯æ¢å¤

    Args:
        url: æ–°é—»URL

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> delete_news_tool("https://example.com/news/123")
    """
    try:
        db = await get_database()
        success = await db.delete_news(url)

        result = {
            "success": success,
            "message": "åˆ é™¤æˆåŠŸ" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
        }

        if success:
            logger.info(f"âœ… åˆ é™¤æˆåŠŸ: {url[:50]}")
        else:
            logger.warning(f"âš ï¸ åˆ é™¤å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ åˆ é™¤å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def get_news_stats_tool(session_id: str = "") -> str:
    """è·å–ç»Ÿè®¡ä¿¡æ¯ - ğŸ“Š æ•°æ®æ¦‚è§ˆ

    åŠŸèƒ½ï¼š
    - è·å–æ•°æ®åº“ä¸­çš„æ–°é—»ç»Ÿè®¡ä¿¡æ¯
    - æ€»æ•°ã€æ¥æºåˆ†å¸ƒã€è¿‘æœŸæ–°å¢ç­‰

    Returns:
        JSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®

    Examples:
        >>> get_news_stats_tool()
    """
    try:
        db = await get_database()
        stats = await db.get_stats(session_id=session_id)

        result = {
            "success": True,
            "stats": stats,
        }

        logger.info(f"âœ… ç»Ÿè®¡ä¿¡æ¯: æ€»æ•° {stats['total']}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def update_event_name_tool(url: str, event_name: str) -> str:
    """æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§° - ğŸ·ï¸ èšåˆåå½’ç±»

    åŠŸèƒ½ï¼š
    - å•ç‹¬æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§°å­—æ®µ
    - ç”¨äºæ–°é—»èšåˆåæ·»åŠ äº‹ä»¶åˆ†ç±»
    - ä¸ä¼šå½±å“å…¶ä»–å­—æ®µ

    Args:
        url: æ–°é—»URL
        event_name: äº‹ä»¶åç§°

    Returns:
        JSONæ ¼å¼çš„æ“ä½œç»“æœ

    Examples:
        >>> # ä¸ºæ–°é—»æ·»åŠ äº‹ä»¶åç§°
        >>> update_event_name_tool(
        ...     url="https://example.com/news/123",
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶"
        ... )
    """
    try:
        db = await get_database()
        success = await db.update_event_name(url, event_name)

        result = {
            "success": success,
            "message": "äº‹ä»¶åç§°å·²æ›´æ–°" if success else "æœªæ‰¾åˆ°è¯¥æ–°é—»",
            "url": url,
            "event_name": event_name,
        }

        if success:
            logger.info(f"âœ… æ›´æ–°äº‹ä»¶åç§°æˆåŠŸ: {url[:50]} -> {event_name}")
        else:
            logger.warning(f"âš ï¸ æ›´æ–°å¤±è´¥: {url[:50]}")

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°äº‹ä»¶åç§°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )


async def batch_update_event_name_tool(urls: str, event_name: str) -> str:
    """æ‰¹é‡æ›´æ–°æ–°é—»çš„äº‹ä»¶åç§° - ğŸ“¦ æ‰¹é‡å½’ç±»

    åŠŸèƒ½ï¼š
    - æ‰¹é‡ä¸ºå¤šæ¡æ–°é—»è®¾ç½®ç›¸åŒçš„äº‹ä»¶åç§°
    - ç”¨äºå°†èšåˆåçš„æ–°é—»å½’ç±»åˆ°åŒä¸€äº‹ä»¶
    - è¿”å›è¯¦ç»†çš„æ›´æ–°ç»Ÿè®¡

    Args:
        urls: URLåˆ—è¡¨JSONå­—ç¬¦ä¸²ï¼ˆå¦‚ '["url1", "url2"]'ï¼‰
        event_name: äº‹ä»¶åç§°

    Returns:
        JSONæ ¼å¼çš„æ‰¹é‡æ“ä½œç»“æœï¼ŒåŒ…å«ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - updated: æ›´æ–°æ•°é‡
        - failed: å¤±è´¥æ•°é‡
        - event_name: äº‹ä»¶åç§°

    Examples:
        >>> urls = '["https://example.com/news/1", "https://example.com/news/2"]'
        >>> batch_update_event_name_tool(
        ...     urls=urls,
        ...     event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶"
        ... )
    """
    try:
        db = await get_database()
        url_list = json.loads(urls) if urls else []

        if not url_list:
            return json.dumps(
                {"success": False, "error": "URLåˆ—è¡¨ä¸ºç©º"},
                ensure_ascii=False,
                indent=2,
            )

        stats = await db.batch_update_event_name(url_list, event_name)

        result = {
            "success": True,
            "updated": stats["updated"],
            "failed": stats["failed"],
            "total": len(url_list),
            "event_name": event_name,
        }

        logger.info(f"âœ… æ‰¹é‡æ›´æ–°äº‹ä»¶åç§°å®Œæˆ: {stats}")
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æ›´æ–°äº‹ä»¶åç§°å¤±è´¥: {e}")
        return json.dumps(
            {"success": False, "error": str(e)}, ensure_ascii=False, indent=2
        )
