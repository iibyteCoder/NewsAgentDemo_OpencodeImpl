"""
æµ‹è¯•å„æœç´¢å¼•æ“æ–°é—»è§£æå™¨ - å®Œæ•´æµ‹è¯•ç‰ˆ

æµ‹è¯•è¦†ç›–ï¼š
- 10ä¸ªæœç´¢å¼•æ“ï¼ˆç™¾åº¦ã€å¿…åº”ã€æœç‹—ã€è°·æ­Œã€360ã€ä»Šæ—¥å¤´æ¡ã€è…¾è®¯ã€ç½‘æ˜“ã€æ–°æµªã€æœç‹ï¼‰
- åçˆ¬è™«æ£€æµ‹
- è‡ªåŠ¨ç¦ç”¨æœºåˆ¶
- å¤šå¼•æ“æ™ºèƒ½æœç´¢
"""

import sys
import io
import asyncio
import time

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ä½¿ç”¨æ–°çš„æ¨¡å—ç»“æ„
from mcp_server.web_browser.config.settings import get_settings
from mcp_server.web_browser.core import get_browser_pool, RateLimiter
from mcp_server.web_browser.engines.factory import EngineFactory
from mcp_server.web_browser.engines.base import SearchResult
from mcp_server.web_browser.tools.search_tools import (
    multi_search,
    _check_anti_bot,
)
from mcp_server.web_browser.utils.helpers import get_random_user_agent, search_result_to_dict

from loguru import logger
from playwright.async_api import Page


# ==================== æµ‹è¯•å•ä¸ªæœç´¢å¼•æ“ ====================

async def test_engine_news(engine_name: str, query: str, num_results: int = 10):
    """æµ‹è¯•å•ä¸ªæœç´¢å¼•æ“çš„æ–°é—»è§£æ

    Args:
        engine_name: å¼•æ“åç§°
        query: æœç´¢å…³é”®è¯
        num_results: è¿”å›ç»“æœæ•°é‡

    Returns:
        (æ˜¯å¦æˆåŠŸ, ç»“æœæ•°é‡, è€—æ—¶ç§’æ•°)
    """
    print(f"\n{'='*70}")
    print(f"ğŸ” æµ‹è¯• {engine_name.upper()} æ–°é—»æœç´¢")
    print(f"å…³é”®è¯: {query}")
    print('='*70)

    start_time = time.time()

    # åˆå§‹åŒ–
    settings = get_settings()
    browser_pool = get_browser_pool(settings)
    rate_limiter = RateLimiter(
        time_window=settings.rate_limit_time_window,
        max_domain_requests=settings.max_domain_requests_per_second,
        max_engine_requests=settings.max_engine_requests_per_second,
    )
    engine_factory = EngineFactory(enabled_engines=settings.enabled_engines)

    try:
        # æ£€æŸ¥å¼•æ“æ˜¯å¦è¢«ç¦ç”¨
        if engine_factory.is_engine_banned(engine_name):
            print(f"\nâš ï¸ å¼•æ“ {engine_name} å½“å‰è¢«ç¦ç”¨")
            return False, 0, 0

        # è·å–å¼•æ“
        engine = engine_factory.get_engine(engine_name)
        if not engine:
            print(f"\nâŒ å¼•æ“ {engine_name} ä¸å¯ç”¨ï¼ˆå¯èƒ½æœªå¯ç”¨ï¼‰")
            return False, 0, 0

        print(f"âœ… å¼•æ“åç§°: {engine.config.name}")

        # åº”ç”¨é€Ÿç‡é™åˆ¶
        search_url = engine.get_search_url(query, num_results, "news")
        domain = engine.extract_domain(search_url)
        await rate_limiter.acquire(domain=domain, engine=engine_name)

        # æ‰§è¡Œæœç´¢
        user_agent = get_random_user_agent()
        async with browser_pool.get_page(user_agent=user_agent) as page:
            print(f"ğŸ“¡ è®¿é—®URL: {search_url[:80]}...")
            await page.goto(search_url, timeout=30000)

            # åçˆ¬è™«æ£€æµ‹
            print(f"ğŸ” æ‰§è¡Œåçˆ¬è™«æ£€æµ‹...")
            is_blocked, block_reason = await _check_anti_bot(page, search_url)
            if is_blocked:
                print(f"\nğŸš¨ æ£€æµ‹åˆ°åçˆ¬è™«æ‹¦æˆª: {block_reason}")
                # ç¦ç”¨è¯¥å¼•æ“
                engine_factory.ban_engine(engine_name, block_reason)
                return False, 0, 0

            print(f"âœ… åçˆ¬è™«æ£€æµ‹é€šè¿‡")

            # è§£æç»“æœ
            results = await engine.search(page, query, num_results, "news")

            # è½¬æ¢ä¸ºå­—å…¸
            results_dict = [search_result_to_dict(r) for r in results]

            elapsed = time.time() - start_time

            print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
            print(f"   ç»“æœæ•°é‡: {len(results_dict)}/{num_results}")
            print(f"   è€—æ—¶: {elapsed:.2f}ç§’")

            # æ˜¾ç¤ºå‰3æ¡ç»“æœ
            if results_dict:
                print(f"\nğŸ“° å‰3æ¡ç»“æœ:")
                print(f"{'-'*70}")

                for i, item in enumerate(results_dict[:3], 1):
                    print(f"\n{i}. {item.get('title', 'N/A')}")
                    print(f"   æ¥æº: {item.get('source', 'N/A')}")
                    print(f"   æ—¶é—´: {item.get('time', 'N/A')}")
                    url = item.get('url', 'N/A')
                    print(f"   é“¾æ¥: {url[:70] if url != 'N/A' else 'N/A'}...")
                    if item.get('summary'):
                        print(f"   æ‘˜è¦: {item['summary'][:80]}...")

            return len(results_dict) > 0, len(results_dict), elapsed

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, 0, elapsed

    finally:
        await browser_pool.close()


# ==================== æµ‹è¯•æ‰€æœ‰æœç´¢å¼•æ“ ====================

async def test_all_engines():
    """æµ‹è¯•æ‰€æœ‰10ä¸ªæœç´¢å¼•æ“"""
    print("\n" + "="*70)
    print("ğŸ”¥ æœç´¢å¼•æ“æ–°é—»è§£æå™¨æµ‹è¯• - å…¨å¼•æ“æµ‹è¯•")
    print("="*70)

    test_query = "äººå·¥æ™ºèƒ½"

    # æ‰€æœ‰10ä¸ªæœç´¢å¼•æ“
    engines = [
        "baidu",      # ç™¾åº¦
        "bing",       # å¿…åº”
        "sogou",      # æœç‹—
        "google",     # è°·æ­Œ
        "360",        # 360æœç´¢
        "toutiao",    # ä»Šæ—¥å¤´æ¡
        "tencent",    # è…¾è®¯æ–°é—»
        "wangyi",     # ç½‘æ˜“æ–°é—»
        "sina",       # æ–°æµªæ–°é—»
        "sohu",       # æœç‹æ–°é—»
    ]

    results = []

    for engine in engines:
        success, count, elapsed = await test_engine_news(engine, test_query)
        results.append({
            "engine": engine,
            "success": success,
            "count": count,
            "elapsed": elapsed
        })

        # ç­‰å¾…ä¸€ä¸‹ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        await asyncio.sleep(2)

    # æ‰“å°æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*70)

    # æŒ‰æˆåŠŸ/å¤±è´¥åˆ†ç»„
    success_engines = [r for r in results if r["success"]]
    failed_engines = [r for r in results if not r["success"]]

    print(f"\nâœ… æˆåŠŸ ({len(success_engines)}/{len(engines)}):")
    for r in success_engines:
        print(f"   {r['engine']:10} - {r['count']} æ¡ç»“æœ, {r['elapsed']:.2f}ç§’")

    if failed_engines:
        print(f"\nâŒ å¤±è´¥ ({len(failed_engines)}/{len(engines)}):")
        for r in failed_engines:
            print(f"   {r['engine']:10} - {r['elapsed']:.2f}ç§’")

    # æ€§èƒ½ç»Ÿè®¡
    if success_engines:
        avg_results = sum(r["count"] for r in success_engines) / len(success_engines)
        avg_elapsed = sum(r["elapsed"] for r in success_engines) / len(success_engines)
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡ç»“æœæ•°: {avg_results:.1f} æ¡")
        print(f"   å¹³å‡è€—æ—¶: {avg_elapsed:.2f} ç§’")

    print()


# ==================== æµ‹è¯•å¤šå¼•æ“æ™ºèƒ½æœç´¢ ====================

async def test_multi_search():
    """æµ‹è¯•å¤šå¼•æ“æ™ºèƒ½æœç´¢ï¼ˆå«è‡ªåŠ¨é™çº§ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ”¥ å¤šå¼•æ“æ™ºèƒ½æœç´¢æµ‹è¯•")
    print("="*70)

    test_query = "ç§‘æŠ€æ–°é—»"

    # æµ‹è¯• auto æ¨¡å¼
    print(f"\nğŸ“¡ æµ‹è¯• AUTO æ¨¡å¼")
    print(f"å…³é”®è¯: {test_query}")
    print('-'*70)

    result = await multi_search(test_query, "auto", 20, "news")

    import json
    result_data = json.loads(result)

    print(f"\nğŸ“Š æœç´¢ç»“æœ:")
    print(f"   å¼•æ“: {result_data.get('engine_name', 'N/A')}")
    print(f"   ç»“æœæ•°: {result_data.get('total', 0)}")
    print(f"   å¯ç”¨å¼•æ“: {result_data.get('available_engines', 'N/A')}")
    print(f"   è¢«ç¦ç”¨å¼•æ“: {result_data.get('banned_engines', 'N/A')}")

    if result_data.get("blocked"):
        print(f"   âš ï¸ è¢«æ‹¦æˆª: {result_data.get('block_reason', 'N/A')}")

    if result_data.get("results"):
        print(f"\nğŸ“° å‰3æ¡ç»“æœ:")
        for i, item in enumerate(result_data["results"][:3], 1):
            print(f"\n{i}. {item.get('title', 'N/A')}")
            print(f"   æ¥æº: {item.get('source', 'N/A')}")

    print()


# ==================== æµ‹è¯•å¼•æ“ç¦ç”¨æœºåˆ¶ ====================

async def test_ban_mechanism():
    """æµ‹è¯•å¼•æ“ç¦ç”¨å’Œè§£ç¦æœºåˆ¶"""
    print("\n" + "="*70)
    print("ğŸ”¥ å¼•æ“ç¦ç”¨æœºåˆ¶æµ‹è¯•")
    print("="*70)

    engine_factory = EngineFactory()

    test_engine = "baidu"

    print(f"\nğŸ“ æµ‹è¯•å¼•æ“: {test_engine}")

    # åˆå§‹çŠ¶æ€
    print(f"\n1ï¸âƒ£ åˆå§‹çŠ¶æ€:")
    print(f"   æ˜¯å¦è¢«ç¦ç”¨: {engine_factory.is_engine_banned(test_engine)}")
    print(f"   è¢«ç¦ç”¨å¼•æ“æ•°: {engine_factory.get_banned_engine_count()}")
    print(f"   å¯ç”¨å¼•æ“æ•°: {engine_factory.get_available_engine_count()}")

    # ç¦ç”¨å¼•æ“ï¼ˆç¬¬1æ¬¡ï¼‰
    print(f"\n2ï¸âƒ£ ç¦ç”¨å¼•æ“ï¼ˆç¬¬1æ¬¡ï¼‰:")
    engine_factory.ban_engine(test_engine, "æµ‹è¯•ç¦ç”¨1")
    ban_info = engine_factory._banned_engines.get(test_engine)
    if ban_info:
        ban_duration = ban_info['unban_time'] - time.time()
        print(f"   ç¦ç”¨æ—¶é•¿: {ban_duration//60} åˆ†é’Ÿ")
        print(f"   ç¦ç”¨æ¬¡æ•°: {ban_info['ban_count']}")
    print(f"   æ˜¯å¦è¢«ç¦ç”¨: {engine_factory.is_engine_banned(test_engine)}")
    print(f"   è¢«ç¦ç”¨å¼•æ“æ•°: {engine_factory.get_banned_engine_count()}")
    print(f"   å¯ç”¨å¼•æ“æ•°: {engine_factory.get_available_engine_count()}")

    # ç¦ç”¨å¼•æ“ï¼ˆç¬¬2æ¬¡ - æ¨¡æ‹Ÿé€’å¢ï¼‰
    print(f"\n3ï¸âƒ£ ç¦ç”¨å¼•æ“ï¼ˆç¬¬2æ¬¡ - æµ‹è¯•é€’å¢æœºåˆ¶ï¼‰:")
    engine_factory.ban_engine(test_engine, "æµ‹è¯•ç¦ç”¨2")
    ban_info = engine_factory._banned_engines.get(test_engine)
    if ban_info:
        ban_duration = ban_info['unban_time'] - time.time()
        print(f"   ç¦ç”¨æ—¶é•¿: {ban_duration//60} åˆ†é’Ÿ")
        print(f"   ç¦ç”¨æ¬¡æ•°: {ban_info['ban_count']}")
    print(f"   æ˜¯å¦è¢«ç¦ç”¨: {engine_factory.is_engine_banned(test_engine)}")

    print()


# ==================== æµ‹è¯•æ–°é—»èšåˆå¹³å° ====================

async def test_news_aggregators():
    """æµ‹è¯•5ä¸ªä¸­æ–‡æ–°é—»èšåˆå¹³å°"""
    print("\n" + "="*70)
    print("ğŸ”¥ æ–°é—»èšåˆå¹³å°ä¸“é¡¹æµ‹è¯•")
    print("="*70)

    test_query = "ä½“è‚²æ–°é—»"

    # 5ä¸ªæ–°é—»èšåˆå¹³å°
    aggregators = ["toutiao", "tencent", "wangyi", "sina", "sohu"]

    print(f"\nå…³é”®è¯: {test_query}")
    print(f"æµ‹è¯•å¹³å°: {', '.join(aggregators)}")

    results = []

    for engine in aggregators:
        success, count, elapsed = await test_engine_news(engine, test_query)
        results.append({
            "engine": engine,
            "success": success,
            "count": count,
            "elapsed": elapsed
        })

        await asyncio.sleep(2)

    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“Š æ–°é—»èšåˆå¹³å°æµ‹è¯•æ€»ç»“")
    print("="*70)

    success_engines = [r for r in results if r["success"]]
    failed_engines = [r for r in results if not r["success"]]

    print(f"\nâœ… æˆåŠŸ ({len(success_engines)}/{len(aggregators)}):")
    for r in success_engines:
        print(f"   {r['engine']:10} - {r['count']} æ¡ç»“æœ, {r['elapsed']:.2f}ç§’")

    if failed_engines:
        print(f"\nâŒ å¤±è´¥ ({len(failed_engines)}/{len(aggregators)}):")
        for r in failed_engines:
            print(f"   {r['engine']:10} - {r['elapsed']:.2f}ç§’")

    print()


# ==================== ä¸»èœå• ====================

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*70)
    print("ğŸ§ª æœç´¢å¼•æ“æµ‹è¯•å¥—ä»¶")
    print("="*70)

    print("\nè¯·é€‰æ‹©æµ‹è¯•ç±»å‹:")
    print("1. æµ‹è¯•æ‰€æœ‰10ä¸ªæœç´¢å¼•æ“")
    print("2. æµ‹è¯•å¤šå¼•æ“æ™ºèƒ½æœç´¢")
    print("3. æµ‹è¯•å¼•æ“ç¦ç”¨æœºåˆ¶")
    print("4. æµ‹è¯•æ–°é—»èšåˆå¹³å°ï¼ˆ5ä¸ªï¼‰")
    print("5. è¿è¡Œå…¨éƒ¨æµ‹è¯•")

    # é»˜è®¤è¿è¡Œå…¨éƒ¨æµ‹è¯•
    choice = "5"

    if choice == "1":
        await test_all_engines()
    elif choice == "2":
        await test_multi_search()
    elif choice == "3":
        await test_ban_mechanism()
    elif choice == "4":
        await test_news_aggregators()
    elif choice == "5":
        print("\nğŸš€ å¼€å§‹è¿è¡Œå…¨éƒ¨æµ‹è¯•...\n")

        await test_all_engines()
        await asyncio.sleep(1)

        await test_multi_search()
        await asyncio.sleep(1)

        await test_ban_mechanism()
        await asyncio.sleep(1)

        await test_news_aggregators()

        print("\n" + "="*70)
        print("âœ… å…¨éƒ¨æµ‹è¯•å®Œæˆï¼")
        print("="*70)


if __name__ == "__main__":
    asyncio.run(main())
