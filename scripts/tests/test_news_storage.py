"""
æµ‹è¯• News Storage MCP Server
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from mcp_server.news_storage.core.database import get_database
from mcp_server.news_storage.core.models import NewsItem, SearchFilter
from loguru import logger


async def test_basic_operations():
    """æµ‹è¯•åŸºæœ¬æ“ä½œ"""
    logger.info("=" * 50)
    logger.info("æµ‹è¯•1: åŸºæœ¬CRUDæ“ä½œ")
    logger.info("=" * 50)

    db = get_database("./data/test_news.db")

    # æµ‹è¯•1: åˆ›å»ºæ–°é—»
    logger.info("\n1ï¸âƒ£ åˆ›å»ºæ–°é—»...")
    news1 = NewsItem(
        title="AIæŠ€æœ¯å–å¾—é‡å¤§çªç ´",
        url="https://example.com/news/ai-breakthrough-001",
        summary="äººå·¥æ™ºèƒ½é¢†åŸŸè¿æ¥é‡å¤§æŠ€æœ¯çªç ´ï¼Œæ–°ç®—æ³•æ€§èƒ½æå‡300%",
        source="ç§‘æŠ€æ—¥æŠ¥",
        publish_time="2026-01-29",
        author="å¼ ä¸‰",
        event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶",
        content="è¿™æ˜¯å®Œæ•´çš„æ–°é—»å†…å®¹...",
        html_content="<p>è¿™æ˜¯HTMLåŸæ–‡å†…å®¹</p>",
        keywords=["AI", "æŠ€æœ¯", "çªç ´"],
        images=["https://example.com/img1.jpg", "https://example.com/img2.jpg"],
        tags=["ç§‘æŠ€", "å‰æ²¿"],
    )

    is_new = db.save_news(news1)
    logger.info(f"   ç»“æœ: {'æ–°å¢' if is_new else 'æ›´æ–°'}")
    logger.info(f"   äº‹ä»¶åç§°: {news1.event_name}")

    # æµ‹è¯•2: æ ¹æ®URLæŸ¥è¯¢
    logger.info("\n2ï¸âƒ£ æ ¹æ®URLæŸ¥è¯¢...")
    found_news = db.get_news_by_url(news1.url)
    if found_news:
        logger.info(f"   æ‰¾åˆ°: {found_news.title}")
        logger.info(f"   æ‘˜è¦: {found_news.summary[:50]}...")
    else:
        logger.error("   æœªæ‰¾åˆ°ï¼")

    # æµ‹è¯•3: æ›´æ–°å†…å®¹
    logger.info("\n3ï¸âƒ£ æ›´æ–°æ–°é—»å†…å®¹...")
    success = db.update_news_content(
        news1.url,
        "è¿™æ˜¯æ›´æ–°åçš„å®Œæ•´æ–°é—»æ­£æ–‡å†…å®¹ï¼ŒåŒ…å«äº†æ›´å¤šç»†èŠ‚...",
        "<p>HTMLå†…å®¹</p>",
    )
    logger.info(f"   ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

    # æµ‹è¯•4: åˆ›å»ºæ›´å¤šæ–°é—»
    logger.info("\n4ï¸âƒ£ æ‰¹é‡åˆ›å»ºæ–°é—»...")
    news_list = [
        NewsItem(
            title="é‡å­è®¡ç®—æ–°è¿›å±•",
            url="https://example.com/news/quantum-001",
            summary="é‡å­è®¡ç®—æœºæˆåŠŸå®ç°1000é‡å­æ¯”ç‰¹ç¨³å®šè¿è¡Œ",
            source="æ–°åç½‘",
            publish_time="2026-01-28",
            keywords=["é‡å­", "è®¡ç®—"],
            tags=["ç§‘æŠ€"],
        ),
        NewsItem(
            title="æ–°èƒ½æºæ±½è½¦é”€é‡æ¿€å¢",
            url="https://example.com/news/ev-001",
            summary="æœ¬æœˆæ–°èƒ½æºæ±½è½¦é”€é‡åŒæ¯”å¢é•¿200%",
            source="è´¢ç»ç½‘",
            publish_time="2026-01-27",
            keywords=["æ±½è½¦", "æ–°èƒ½æº"],
            tags=["è´¢ç»"],
        ),
    ]

    for news in news_list:
        db.save_news(news)

    logger.info(f"   åˆ›å»ºäº† {len(news_list)} æ¡æ–°é—»")

    # æµ‹è¯•5: è·å–æœ€è¿‘æ–°é—»
    logger.info("\n5ï¸âƒ£ è·å–æœ€è¿‘æ–°é—»...")
    recent = db.get_recent_news(limit=10)
    logger.info(f"   æ‰¾åˆ° {len(recent)} æ¡æœ€è¿‘æ–°é—»")
    for news in recent[:3]:
        logger.info(f"   - {news.title} ({news.source})")

    # æµ‹è¯•6: æœç´¢åŠŸèƒ½
    logger.info("\n6ï¸âƒ£ æœç´¢åŠŸèƒ½æµ‹è¯•...")

    # å…³é”®è¯æœç´¢
    filter1 = SearchFilter(keyword="AI", limit=10)
    results1 = db.search_news(filter1)
    logger.info(f"   å…³é”®è¯'AI': æ‰¾åˆ° {len(results1)} æ¡")

    # æŒ‰æ¥æºç­›é€‰
    filter2 = SearchFilter(source="ç§‘æŠ€æ—¥æŠ¥", limit=10)
    results2 = db.search_news(filter2)
    logger.info(f"   æ¥æº'ç§‘æŠ€æ—¥æŠ¥': æ‰¾åˆ° {len(results2)} æ¡")

    # æŒ‰æ ‡ç­¾ç­›é€‰
    filter3 = SearchFilter(tags=["ç§‘æŠ€"], limit=10)
    results3 = db.search_news(filter3)
    logger.info(f"   æ ‡ç­¾'ç§‘æŠ€': æ‰¾åˆ° {len(results3)} æ¡")

    # æŒ‰äº‹ä»¶åç§°ç­›é€‰
    filter4 = SearchFilter(event_name="2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶", limit=10)
    results4 = db.search_news(filter4)
    logger.info(f"   äº‹ä»¶åç§°'2026å¹´AIæŠ€æœ¯çªç ´äº‹ä»¶': æ‰¾åˆ° {len(results4)} æ¡")

    # æµ‹è¯•7: ç»Ÿè®¡ä¿¡æ¯
    logger.info("\n7ï¸âƒ£ è·å–ç»Ÿè®¡ä¿¡æ¯...")
    stats = db.get_stats()
    logger.info(f"   æ€»æ•°: {stats['total']}")
    logger.info(f"   æœ€è¿‘7å¤©: {stats['recent_week']}")
    logger.info(f"   æ¥æºåˆ†å¸ƒ:")
    for source, count in stats['by_source'].items():
        logger.info(f"     - {source}: {count}")

    # æµ‹è¯•8: åˆ é™¤æ–°é—»
    logger.info("\n8ï¸âƒ£ åˆ é™¤æ–°é—»...")
    delete_url = "https://example.com/news/ev-001"
    success = db.delete_news(delete_url)
    logger.info(f"   åˆ é™¤ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

    logger.info("\nâœ… åŸºæœ¬æ“ä½œæµ‹è¯•å®Œæˆï¼")


async def test_batch_operations():
    """æµ‹è¯•æ‰¹é‡æ“ä½œ"""
    logger.info("\n" + "=" * 50)
    logger.info("æµ‹è¯•2: æ‰¹é‡æ“ä½œ")
    logger.info("=" * 50)

    db = get_database("./data/test_news.db")

    # æ‰¹é‡ä¿å­˜
    logger.info("\n1ï¸âƒ£ æ‰¹é‡ä¿å­˜æ–°é—»...")
    batch_news = [
        NewsItem(
            title=f"æµ‹è¯•æ–°é—» {i}",
            url=f"https://example.com/test/batch-{i}",
            summary=f"è¿™æ˜¯ç¬¬ {i} æ¡æµ‹è¯•æ–°é—»",
            source="æµ‹è¯•æ¥æº",
            keywords=["æµ‹è¯•"],
        )
        for i in range(10)
    ]

    stats = db.save_news_batch(batch_news)
    logger.info(f"   æ–°å¢: {stats['added']}")
    logger.info(f"   æ›´æ–°: {stats['updated']}")
    logger.info(f"   å¤±è´¥: {stats['failed']}")

    # å†æ¬¡ä¿å­˜ç›¸åŒæ•°æ®ï¼ˆæµ‹è¯•å»é‡ï¼‰
    logger.info("\n2ï¸âƒ£ æµ‹è¯•å»é‡ï¼ˆå†æ¬¡ä¿å­˜ç›¸åŒæ•°æ®ï¼‰...")
    stats = db.save_news_batch(batch_news)
    logger.info(f"   æ–°å¢: {stats['added']} (åº”è¯¥ä¸º0)")
    logger.info(f"   æ›´æ–°: {stats['updated']} (åº”è¯¥ä¸º10)")

    logger.info("\nâœ… æ‰¹é‡æ“ä½œæµ‹è¯•å®Œæˆï¼")


async def test_search_features():
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    logger.info("\n" + "=" * 50)
    logger.info("æµ‹è¯•3: é«˜çº§æœç´¢åŠŸèƒ½")
    logger.info("=" * 50)

    db = get_database("./data/test_news.db")

    # åˆ›å»ºä¸åŒç±»å‹çš„æ–°é—»
    logger.info("\n1ï¸âƒ£ åˆ›å»ºæµ‹è¯•æ•°æ®...")
    test_data = [
        NewsItem(
            title="Python 3.13å‘å¸ƒ",
            url="https://example.com/tech/python-313",
            summary="Python 3.13æ­£å¼å‘å¸ƒï¼Œæ€§èƒ½å¤§å¹…æå‡",
            source="æŠ€æœ¯ç¤¾åŒº",
            keywords=["Python", "ç¼–ç¨‹"],
            tags=["æŠ€æœ¯", "ç¼–ç¨‹è¯­è¨€"],
        ),
        NewsItem(
            title="JavaScriptæ¡†æ¶å¯¹æ¯”",
            url="https://example.com/tech/js-frameworks",
            summary="React vs Vue vs Angularï¼Œå“ªä¸ªæ›´å¥½ï¼Ÿ",
            source="å‰ç«¯å‘¨åˆŠ",
            keywords=["JavaScript", "å‰ç«¯"],
            tags=["æŠ€æœ¯", "å‰ç«¯å¼€å‘"],
        ),
        NewsItem(
            title="Rustè¯­è¨€å…¥é—¨æŒ‡å—",
            url="https://example.com/tech/rust-guide",
            summary="Rustè¯­è¨€è¯¦ç»†æ•™ç¨‹ï¼Œä»é›¶å¼€å§‹",
            source="æŠ€æœ¯ç¤¾åŒº",
            keywords=["Rust", "ç¼–ç¨‹"],
            tags=["æŠ€æœ¯", "ç³»ç»Ÿç¼–ç¨‹"],
        ),
    ]

    for news in test_data:
        db.save_news(news)

    # æµ‹è¯•å„ç§æœç´¢
    logger.info("\n2ï¸âƒ£ æµ‹è¯•å…³é”®è¯æœç´¢...")
    filters = [
        SearchFilter(keyword="Python", limit=10),
        SearchFilter(keyword="JavaScript", limit=10),
        SearchFilter(keyword="æ€§èƒ½", limit=10),
    ]

    for f in filters:
        results = db.search_news(f)
        logger.info(f"   å…³é”®è¯'{f.keyword}': {len(results)} æ¡")

    logger.info("\n3ï¸âƒ£ æµ‹è¯•æ¥æºç­›é€‰...")
    filter_source = SearchFilter(source="æŠ€æœ¯ç¤¾åŒº", limit=10)
    results = db.search_news(filter_source)
    logger.info(f"   æ¥æº'æŠ€æœ¯ç¤¾åŒº': {len(results)} æ¡")

    logger.info("\n4ï¸âƒ£ æµ‹è¯•æ ‡ç­¾ç­›é€‰...")
    filter_tags = SearchFilter(tags=["æŠ€æœ¯"], limit=10)
    results = db.search_news(filter_tags)
    logger.info(f"   æ ‡ç­¾'æŠ€æœ¯': {len(results)} æ¡")

    logger.info("\n5ï¸âƒ£ æµ‹è¯•ç»„åˆæœç´¢...")
    filter_combo = SearchFilter(
        keyword="ç¼–ç¨‹", source="æŠ€æœ¯ç¤¾åŒº", limit=10
    )
    results = db.search_news(filter_combo)
    logger.info(f"   å…³é”®è¯'ç¼–ç¨‹' + æ¥æº'æŠ€æœ¯ç¤¾åŒº': {len(results)} æ¡")

    logger.info("\nâœ… æœç´¢åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ News Storage æµ‹è¯•å¼€å§‹\n")

    try:
        await test_basic_operations()
        await test_batch_operations()
        await test_search_features()

        logger.info("\n" + "=" * 50)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
