"""
åˆ†æå„æœç´¢å¼•æ“çš„ç¨³å®šHTMLç»“æ„
"""

import sys
import io
from bs4 import BeautifulSoup

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def analyze_structure(html_file, engine_name):
    """åˆ†æå¼•æ“çš„ç¨³å®šç»“æ„"""
    print(f"\n{'='*60}")
    print(f"{engine_name} ç¨³å®šç»“æ„åˆ†æ")
    print('='*60)

    with open(html_file, 'r', encoding='utf-8') as f:
        html = f.read()

    soup = BeautifulSoup(html, 'html.parser')

    # æŸ¥æ‰¾åŒ…å«é“¾æ¥çš„ç»“æ„
    print("\nğŸ”— é“¾æ¥ç»“æ„:")

    if engine_name == "å¿…åº”":
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å« href çš„ a æ ‡ç­¾
        links = soup.find_all('a', href=True)
        news_links = [l for l in links if '/news/' in l.get('href', '') or l.get('data-title')]

        print(f"æ‰¾åˆ° {len(news_links)} ä¸ªæ–°é—»é“¾æ¥")

        for i, link in enumerate(news_links[:3]):
            print(f"\né“¾æ¥ {i+1}:")
            print(f"  href: {link.get('href', '')[:80]}")

            # æŸ¥æ‰¾çˆ¶çº§divçš„å±æ€§
            parent = link.find_parent('div')
            if parent:
                print(f"  çˆ¶çº§divå±æ€§:")
                for attr in ['class', 'data-title', 'data-url', 'data-author', 'role']:
                    val = parent.get(attr)
                    if val:
                        print(f"    {attr}: {str(val)[:100]}")

            # æŸ¥æ‰¾æ ‡é¢˜
            title = link.find(['h2', 'h3', 'h4'])
            if title:
                print(f"  æ ‡é¢˜æ ‡ç­¾: {title.name}, class: {title.get('class')}")
                print(f"  æ ‡é¢˜æ–‡æœ¬: {title.get_text(strip=True)[:60]}")

    elif engine_name == "è°·æ­Œ":
        # æŸ¥æ‰¾æ‰€æœ‰ /url= å¼€å¤´çš„é“¾æ¥
        links = soup.find_all('a', href=True)
        url_links = [l for l in links if l.get('href', '').startswith('/url?')]

        print(f"æ‰¾åˆ° {len(url_links)} ä¸ªæ–°é—»é“¾æ¥")

        for i, link in enumerate(url_links[:3]):
            print(f"\né“¾æ¥ {i+1}:")
            href = link.get('href', '')
            print(f"  href: {href[:80]}...")

            # æŸ¥æ‰¾æ ‡é¢˜ç»“æ„
            parent = link.find_parent('div')
            if parent:
                # æŸ¥æ‰¾h3
                h3 = parent.find('h3')
                if h3:
                    print(f"  h3 class: {h3.get('class')}")
                    print(f"  æ ‡é¢˜: {h3.get_text(strip=True)[:60]}")

                # æŸ¥æ‰¾å†…å®¹div
                content_divs = parent.find_all('div')
                for div in content_divs[:3]:
                    classes = div.get('class', [])
                    if any(cls for cls in classes if len(cls) > 5 and cls[0].isupper()):
                        print(f"  å†…å®¹div class: {classes}")
                        text = div.get_text(strip=True)[:60]
                        if text:
                            print(f"  æ–‡æœ¬: {text}")

    elif engine_name == "æœç‹—":
        # æŸ¥æ‰¾æ‰€æœ‰ç»“æœ
        all_divs = soup.find_all('div')
        result_divs = [d for d in all_divs if d.find('a') and d.find('h3')]

        print(f"æ‰¾åˆ° {len(result_divs)} ä¸ªå¯èƒ½çš„ç»“æœdiv")

        for i, div in enumerate(result_divs[:3]):
            print(f"\nç»“æœ {i+1}:")

            link = div.find('a', href=True)
            if link:
                href = link.get('href', '')
                print(f"  href: {href[:80]}...")

            h3 = div.find('h3')
            if h3:
                print(f"  h3 class: {h3.get('class')}")
                print(f"  æ ‡é¢˜: {h3.get_text(strip=True)[:60]}")

            # æŸ¥æ‰¾çˆ¶çº§divçš„class
            parent = div.find_parent('div')
            if parent and parent.get('class'):
                print(f"  çˆ¶çº§class: {parent.get('class')}")


def main():
    """ä¸»å‡½æ•°"""
    engines = {
        "å¿…åº”": "search_engine_demos/å¿…åº”_news_cleaned.html",
        "è°·æ­Œ": "search_engine_demos/è°·æ­Œ_news_cleaned.html",
        "æœç‹—": "search_engine_demos/æœç‹—_news_cleaned.html",
    }

    for engine_name, html_file in engines.items():
        try:
            analyze_structure(html_file, engine_name)
        except Exception as e:
            print(f"\nâŒ {engine_name} åˆ†æå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
