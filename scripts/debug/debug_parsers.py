"""
è°ƒè¯•æœç´¢å¼•æ“é¡µé¢è§£æ
"""

import sys
import io
import asyncio

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from mcp_server.baidu_search.browser_pool import get_browser_pool


async def debug_engine(engine_name: str, url: str, selectors: list):
    """è°ƒè¯•å•ä¸ªæœç´¢å¼•æ“çš„é¡µé¢ç»“æ„"""
    print(f"\n{'='*60}")
    print(f"è°ƒè¯• {engine_name}")
    print(f"URL: {url}")
    print('='*60)

    browser_pool = get_browser_pool(
        max_concurrent=1,
        proxy={"server": "localhost:7897"}
    )

    try:
        async with browser_pool.get_page() as page:
            await page.goto(url, timeout=30000)
            await asyncio.sleep(3)

            # è·å–é¡µé¢æ ‡é¢˜
            title = await page.title()
            print(f"\né¡µé¢æ ‡é¢˜: {title}")

            # æµ‹è¯•å„ä¸ªé€‰æ‹©å™¨
            for selector_desc, selector in selectors:
                print(f"\n--- æµ‹è¯•é€‰æ‹©å™¨: {selector_desc} ---")
                print(f"CSS: {selector}")

                elements = await page.query_selector_all(selector)
                print(f"æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")

                if elements:
                    # æ˜¾ç¤ºå‰3ä¸ªå…ƒç´ çš„HTMLç»“æ„
                    for i in range(min(3, len(elements))):
                        elem = elements[i]
                        print(f"\n  å…ƒç´  {i+1}:")
                        print(f"    æ ‡ç­¾: {await elem.evaluate('e => e.tagName')}")

                        # è·å–innerHTMLçš„å‰200ä¸ªå­—ç¬¦
                        inner_html = await elem.inner_html()
                        print(f"    HTML: {inner_html[:200]}...")

                        # å°è¯•æå–æ ‡é¢˜
                        title_elem = await elem.query_selector("h1, h2, h3, h4, a")
                        if title_elem:
                            text = await title_elem.inner_text()
                            print(f"    æ ‡é¢˜æ–‡æœ¬: {text[:100]}")

                        # å°è¯•æå–é“¾æ¥
                        link_elem = await elem.query_selector("a[href]")
                        if link_elem:
                            href = await link_elem.get_attribute("href")
                            print(f"    é“¾æ¥: {href[:100]}")

    except Exception as e:
        print(f"\nâŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        await browser_pool.close()


async def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸ” æœç´¢å¼•æ“é¡µé¢ç»“æ„è°ƒè¯•")
    print("="*60)

    test_query = "ä½ å¥½"

    debug_tasks = [
        ("ç™¾åº¦æ–°é—»", f"https://www.baidu.com/s?rtt=1&bsst=1&cl=2&tn=news&ie=utf-8&word={test_query}", [
            ("ç»“æœå®¹å™¨", "div.result"),
            ("æ–°é—»å®¹å™¨", "div[class*='result']"),
            ("ä»»æ„å®¹å™¨", "div"),
        ]),
        ("è°·æ­Œæ–°é—»", f"https://www.google.com/search?q={test_query}&tbm=nws", [
            ("Gx5Zadå®¹å™¨", "div[class*='Gx5Zad']"),
            ("xpdå®¹å™¨", "div[class*='xpd']"),
            ("æ–°é—»å¡ç‰‡", "div[class*='SoGUE']"),
        ]),
        ("æœç‹—æ–°é—»", f"https://www.sogou.com/news?query={test_query}", [
            ("ç»“æœå®¹å™¨", "div[class*='results']"),
            ("æ–°é—»å®¹å™¨", "div[class*='news']"),
            ("RBå®¹å™¨", "div.rb"),
            ("ä»»æ„å®¹å™¨", "div"),
        ]),
    ]

    for engine_name, url, selectors in debug_tasks:
        await debug_engine(engine_name, url, selectors)
        await asyncio.sleep(2)


if __name__ == "__main__":
    asyncio.run(main())
